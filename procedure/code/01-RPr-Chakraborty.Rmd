---
title: "Reproduction of Chakraborty 2021: An intracategorical analysis of COVID-19 and people with disabilities"
author: "Joseph Holler, Junyi Zhou, Peter Kedron, Drew An-Pham, Derrick Burt, William Procter"
date: "`r Sys.Date()`"
output: html_document
editor_options:
  markdown:
    wrap: sentence
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../../docs") })
---

Version 2.0 \| First Created July 7, 2021 \| Updated June 26, 2023

# Abstract

Chakraborty (2021) investigates the relationships between COVID-19 rates and demographic characteristics of people with disabilities by county in the continental United States.
The aim of the study is to investigate whether people with disabilities (PwDs) face disproportionate challenges due to COVID-19.
To do so, Chakraborty examines the statistical relationship between county incidence rates of COVID-19 cases and county-level percentages of people with disabilities and different socio-demographic characteristics.
Specifically, Chakraborty tests county-level bivariate correlations between COVID-19 incidence against the percentage of disability as one hypothesis, and tests correlation between COVID-19 incidence and percentage of people with disabilities in 18 different socio-demographic categories of race, ethnicity, poverty status, age, and biological sex.
Chakraborty then re-tests for the same county-level associations while controlling for spatial dependence.
Spatial dependence is controlled by constructing generalized estimating equation (GEE) models using a combination of state and spatial clusters of COVID-19 incidence as to define the GEE clusters.
One GEE model is constructed for each of the four types of socio-demographic category: race, ethnicity, age, and biological sex.
Chakraborty (2021) finds significant positive relationships between COVID-19 rates and socially vulnerable demographic categories of race, ethnicity, poverty status, age, and biological sex.

This reproduction study is motivated by expanding the potential impact of Chakraborty's study for policy, research, and teaching purposes.
Measuring the relationship between COVID-19 incidence and socio-demographic and disability characteristics can provide important information for public health policy-making and resource allocation.
A fully reproducible study will increase the accessibility, transparency, and potential impact of Chakraborty's (2021) study by publishing a compendium complete with metadata, data, and code.
This will allow other researchers to review, extend, and modify the study and will allow students of geography and spatial epidemiology to learn from the study design and methods.

In this reproduction, we will attempt to identically reproduce all of the results from the original study.
This will include the map of county level distribution of COVID-19 incidence rates (Fig. 1), the summary statistics for disability and sociodemographic variables and bivariate correlations with county-level COVID-19 incidence rate (Table 1), and the GEE models for predicting COVID-19 county-level incidence rate (Table 2).
A successful reproduction should be able to generate identical results as published by Chakraborty (2021).

The reproduction study data and code are available in public a GitHub repository at [github.com/HEGSRR/RPr-Chakraborty2021](https://github.com/HEGSRR/RPr-Chakraborty2021) and the analysis plans and reports are registered with OSF at <https://doi.org/10.17605/OSF.IO/S5MTQ>.
The reproduction is implemented with R markdown using the `SpatialEpi` package for the Kulldorff spatial scan statistic packages and the `geepack` package for the generalized estimating equation.

Chakraborty, J.
2021.
Social inequities in the distribution of COVID-19: An intra-categorical analysis of people with disabilities in the U.S.
*Disability and Health Journal* 14:1-5.
<https://doi.org/10.1016/j.dhjo.2020.101007>

## Keywords

COVID-19; Disability; Intersectionality; Race/ethnicity; Poverty; Reproducibility

# Study design

The aim of this reproduction study is to implement the original study as closely as possible to reproduce the map of county level distribution of COVID-19 incidence rate, the summary statistics and bivariate correlation for disability characteristics and COVID-19 incidence, and the generalized estimating equations.
Our two confirmatory hypotheses are that we will be able to exactly reproduce Chakraborty's results as presented in table 1 and table 2.
Stated as null reproduction study hypotheses (RPr-H):

> RPr-H1: There is a less than perfect match between Chakraborty's bivariate correlation coefficient for each disability/sociodemographic variable and COVID-19 incidence rate and our bivariate correlation coefficient for each disability/sociodemographic variable and COVID-19 incidence rate.

> RPr-H2: There is a less than perfect match between Chakraborty's beta coefficient for the GEE of each disability/sociodemographic variable and our beta coefficient for the GEE of each disability/sociodemographic variable.

There are multiple models being tested within each of the two hypotheses.
That is, H1 and H2 both encompass five models, including one for each dimension of socio-demographics: race, ethnicity, poverty status, age, and biological sex.

# Original study design

The original study is **observational**, with the **exploratory** objective of determining "whether COVID-19 incidence is significantly greater in counties containing higher percentages of socio-demographically disadvantaged [people with disabilities], based on their race, ethnicity, poverty status, age, and biological sex" (Chakraborty 2021).

In the original study, 18 implicit bivariate hypotheses are tested for correlation between COVID-19 cumulative incidence rates and specific categories of PwDs at the county level.
Although the original publication does not state null hypotheses for each bivariate correlation, we may formulate the original research hypotheses (OR-H) as follows:

> OR-H1.1: There is no correlation between the COVID-19 incidence rate and the percentage of people with disabilities at the county level.
> OR-H1.2: There is no correlation between the COVID-19 incidence rate and the percentage of white people with disabilities at the county level.
> ... OR-H1.18 There is no correlation between the COVID-19 incidence rate and the percentage of female people with disabilities at the county level.

Five multi-variate hypotheses are tested for associations between COVID-19 cumulative incidence rates and subgroups of PwDs at the county level.
Although the original publication does not state null hypotheses for each model, we may formulate them as follows:

> OR-H2.1: The percentages of people with disability, categorized by race, are not associated with COVID-19 incidence at the county level when accounting for the state and risk level of COVID-19 clusters.
> ... OR-H2.5: The percentages of people with disability, categorized by gender, are not associated with COVID-19 incidence at the county level when accounting for the state and risk level of COVID-19 clusters.

The **spatial extent** of the study is the continental United States (48 contiguous states and Washington D.C.) The **spatial scale** of the analysis is at the county level.
Both COVID-19 incidence rates and demographic variables are all measured at the county level.
The **temporal extent** of the COVID-19 data ranges from 1/22/2020 (when John Hopkins began collecting the data) to 8/1/2020 (when the data was retrieved for the original study).
The data on disability and sociodemographic characteristics come from the U.S.
Census American Community Survey (ACS) five-year estimates for 2018 (2014-2018).

There is no **randomization** in the original study.

![](../../docs/report/workflow.jpg "Workflow diagram")

# Computational environment

The study was originally conducted using SaTScan software to implement the Kulldorff spatial scan statistic.
Other software are not specified in the publication; however data files suggest and communication with the author verifies that spatial analysis and mapping was conducted in ArcGIS, generalized estimating equation (GEE) models were calculated in SPSS, and the SaTScan software version was `9.6`.

This reproduction study uses R, including the SpatialEpi package for the Kulldorff spatial scan statistics and the geepack package for GEE models.

```{r setup, include = FALSE}
# list of required packages
packages <- c(
  "tidycensus", "tidyverse", "downloader", "sf", "classInt", "readr",
  "here", "s2", "pastecs", "tmap", "SpatialEpi", "svDialogs",
  "geepack", "knitr", "kableExtra", "foreign", "broom", "dotwhisker", "dotenv"
)

# load and install required packages
if(!require(groundhog)){
  install.packages("groundhog")
  require(groundhog)
}

if(!require(here)){
  install.packages("here")
  require(here)
}

groundhog.day <- "2023-06-26"
set.groundhog.folder(here("data", "scratch", "groundhog"))

groundhog.library(packages, groundhog.day)
# you may need to...
# install a correct version of R
# install the rstudioapi package with install.packages("rstudioapi")
# respond OK in the console to permit groundhog to install packages
# restart the R session and rerun this code to load installed packages
# In RStudio, restart r with Session -> Restart Session

# non-groundhog method for installing packages:
# lapply(packages, library, character.only = TRUE)

# save the R processing environment
writeLines(
  capture.output(sessionInfo()),
  here("procedure", "environment", paste0("r-environment-", Sys.Date(), ".txt"))
)

# set up default knitr parameters
knitr::opts_chunk$set(
  echo = FALSE,
  fig.width = 8,
  fig.path = paste0(here("results", "figures"), "/")
)
```

# Data

## ACS Socio-demographic data

The American Community Survey (ACS) five-year estimate (2014-2018) variables used in the study are outlined in the table below.
Details on ACS data collection can be found at <https://www.census.gov/topics/health/disability/guidance/data-collection-acs.html> and details on sampling methods and accuracy can be found at <https://www.census.gov/programs-surveys/acs/technical-documentation/code-lists.html>.

|                            Variable Name in Study                            |                                               ACS Variable name                                                |
|:----------------------------------------------------------------------------:|:--------------------------------------------------------------------------------------------------------------:|
| percent of total civilian non-institutionalized population with a disability |                                                 S1810_C03_001E                                                 |
|                                   **Race**                                   |                                                                                                                |
|                      percent w disability: White alone                       |                                                 S1810_C03_004E                                                 |
|                      percent w disability: Black alone                       |                                                 S1810_C03_005E                                                 |
|                    percent w disability: Native American                     |                                                 S1810_C03_006E                                                 |
|                      percent w disability: Asian alone                       |                                                 S1810_C03_007E                                                 |
|                       percent w disability: Other race                       |                                                 S1810_C03_009E                                                 |
|                                **Ethnicity**                                 |                                                                                                                |
|                   percent w disability: Non-Hispanic White                   |                                                S1810_C03_0011E                                                 |
|                        percent w disability: Hispanic                        |                                                 S1810_C03_012E                                                 |
|                 percent w disability: Non-Hispanic non-White                 | (S1810_C02_001E - S1810_C02_011E - S1810_C02_012E) / (S1810_C01_001E - S1810_C01_011E - S1810_C01_012E) \* 100 |
|                       percent w disability: Other race                       |                                                 S1810_C03_009E                                                 |
|                                 **Poverty**                                  |                                                                                                                |
|                  percent w disability: Below poverty level                   |                         (C18130_004E + C18130_011E + C18130_018E) / C18130_001E \* 100                         |
|                  percent w disability: Above poverty level                   |                         (C18130_005E + C18130_012E + C18130_019E) / C18130_001E \* 100                         |
|                                   **Age**                                    |                                                                                                                |
|                          percent w disability: 5-17                          |                                                 S1810_C03_014E                                                 |
|                         percent w disability: 18-34                          |                                                 S1810_C03_015E                                                 |
|                         percent w disability: 35-64                          |                                                 S1810_C03_016E                                                 |
|                         percent w disability: 65-74                          |                                                 S1810_C03_017E                                                 |
|                          percent w disability: 75+                           |                                                 S1810_C03_018E                                                 |
|                              **Biological sex**                              |                                                                                                                |
|                          percent w disability: male                          |                                                 S1810_C03_001E                                                 |
|                         percent w disability: female                         |                                                 S1810_C03_003E                                                 |

: Disability Subgroup Variables

American Community Survey (ACS) data for sociodemographic subcategories of people with disabilities can be accessed by using the `tidycensus` package to query the Census API. This requires an API key which can be acquired at [api.census.gov/data/key_signup.html](https://api.census.gov/data/key_signup.html).

```{r API-Load-ACS, eval=FALSE}
# If you wish to use a census API key, run the census_api_key() function in the console

# Query disability demographic data with geographic boundaries
acs <- get_acs(
  geography = "county",
  table = "S1810",
  year = 2018,
  output = "wide",
  cache_table = TRUE,
  geometry = TRUE,
  keep_geo_vars = TRUE
)

# Query poverty and disability data
acs_pov <- get_acs(
  geography = "county",
  table = "C18130",
  year = 2018,
  output = "wide",
  cache_table = TRUE
)

# Query state geographic data
state <- get_acs(
  geography = "state",
  year = 2018,
  variables = c("B01001_001"),
  geometry = TRUE,
  keep_geo_vars = TRUE
)

# Save query results
saveRDS(acs, here("data", "raw", "public", "acs.RDS"))          #file path of where to store in our directory
saveRDS(acs_pov, here("data", "raw", "public", "acs_pov.RDS"))
saveRDS(state, here("data", "raw", "public", "state.RDS"))
```

```{r load-acs}
acs <- readRDS(here("data", "raw", "public", "acs.RDS"))        #store as data and load into project
acs_pov <- readRDS(here("data", "raw", "public", "acs_pov.RDS"))
state <- readRDS(here("data", "raw", "public", "state.RDS"))
```

### ACS data transformations

The original study extent is the lower 48 states and Washington D.C. Therefore, Alaska, Hawai'i and Puerto Rico are removed from the data (workflow step 1).
Data on people with disabilities in poverty is derived from a different census table (C18130) than data on people with disabilities and age, race, ethnicity, age, and biological sex (S1810).
Therefore, join the poverty data to the other data using the GEOID (workflow step 3).
Also transform the ACS geographic data into Contiguous USA Albers Equal Area projection and fix geometry errors.

```{r filter-join-acs}
# Overwrite acs to remove Alaska, Hawaii & Puerto Rico,
# transform coordinate system and fix geometries
acs <- filter(acs, !STATEFP %in% c("02", "15", "72")) %>%
  st_transform(5070) %>%
  st_make_valid()

# Overwrite state to emove Alaska, Hawaii & Puerto Rico,
state <- filter(state, !STATEFP %in% c("02", "15", "72")) %>%
  st_transform(5070)

# Join poverty data to disability data
acs <- left_join(acs, acs_pov, by = "GEOID")
rm(acs_pov)
```

Optionally, save the raw ACS data to `data/raw/public/acs.gpkg` for use in GIS software.

```{r save-ACS, message = F, eval = FALSE}
# Save downloaded acs data to acs.gpkg
write_sf(
  acs,
  here("data", "derived", "public", "acs.gpkg"),
  layer = "acs"
)
write_sf(
  state,
  here("data", "derived", "public", "acs.gpkg"),
  layer = "state"
)
```

Calculate independent socio-demographic variables of people with disabilities as percentages for each sub-category of disability (race, ethnicity, poverty, age, and biological sex) and remove raw census data from the data frame (workflow step 4).
Reproject the data into an Albers equal area conic projection.

```{r Preprocess-ACS}
# calculate percentages: subgroup population divided by total population
acs_derived <- mutate(acs,
  dis_pct = S1810_C02_001E / S1810_C01_001E * 100,                              #Would help here if the intermediate variables were identified in English, not encoded
  white_pct = S1810_C02_004E / S1810_C01_001E * 100,
  black_pct = S1810_C02_005E / S1810_C01_001E * 100,
  native_pct = S1810_C02_006E / S1810_C01_001E * 100,
  asian_pct = S1810_C02_007E / S1810_C01_001E * 100,
  other_pct =                                                                   #Other is a vague variable name, should rename to "other_race_pct"
    (S1810_C02_008E + S1810_C02_009E + S1810_C02_010E) / S1810_C01_001E * 100,
  non_hisp_white_pct = S1810_C02_011E / S1810_C01_001E * 100,
  hisp_pct = S1810_C02_012E / S1810_C01_001E * 100,
  non_hisp_non_white_pct =
    (S1810_C02_001E - S1810_C02_012E - S1810_C02_011E) / S1810_C01_001E * 100,
  bpov_pct = (C18130_004E + C18130_011E + C18130_018E) / C18130_001E * 100,
  apov_pct = (C18130_005E + C18130_012E + C18130_019E) / C18130_001E * 100,
  pct_5_17 = S1810_C02_014E / S1810_C01_001E * 100,
  pct_18_34 = S1810_C02_015E / S1810_C01_001E * 100,
  pct_35_64 = S1810_C02_016E / S1810_C01_001E * 100,
  pct_65_74 = S1810_C02_017E / S1810_C01_001E * 100,
  pct_75 = S1810_C02_018E / S1810_C01_001E * 100,
  male_pct = S1810_C02_002E / S1810_C01_001E * 100,
  female_pct = S1810_C02_003E / S1810_C01_001E * 100
)

# select only relevant geographic identifiers and derived percentages           #Select only the columns that we care about: geographic identifiers and our derived %'s
acs_derived <- acs_derived %>%
  select(
    fips = GEOID,
    statefp = STATEFP,
    county = NAME.x,
    county_st = NAME,
    contains("pct")                                                             #Selects all the new % columns using one line of code...If the column name contains "pct"
  )
```

## COVID-19 data

Data on COVID-19 cases from the Johns Hopkins University dashboard have been provided directly with the research compendium because the data is no longer available online in the state in which it was downloaded on August 1, 2020.
The dashboard and cumulative counts of COVID-19 cases and deaths were continually updated, so an exact reproduction required communication with the original author, Jayajit Chakraborty, for assistance with provision of data from August 1, 2020.
The data includes an estimate of the total population (`POP_ESTIMA`) and confirmed COVID-19 cases (`Confirmed`).
The COVID-19 case data expresses cumulative count of reported COVID-19 from 1/22/2020 to 8/1/2020.
Although metadata for this particular resource is no longer available from the original source, one can reasonably assume that the total population estimate was based on the 2014-2018 5-year ACS estimate, as the 2019 estimates data had not been released yet.\*\*\*\*\*\*\*UNCERTAINTY\*\*\*\*\*\*\*

Versions of the data can be found at the John Hopkins CCSE COVID-19 Data Repository (<https://github.com/CSSEGISandData/COVID-19>).
However, archived data only provides summaries at the national scale.
We received the COVID-19 case data through 8/1/2020 at the county level from the author, as there is no readily apparent way to access archived data from the Johns Hopkins University Center for Systems Science Engineering database.

```{r load-covid-data}
covid <- read_sf(here("data", "raw", "public", "covidcase080120.gpkg"))         #Reads in the Covid data

# select and rename the fips code, population, cases, and x,y coordinates       #renames columns to more readable and specific titles
covid <- select(covid,
  fips = FIPS,
  pop = POP_ESTIMA,
  cases = Confirmed,
  x = X, y = Y
)
```

### COVID-19 data transformations

Calculate the COVID incidence rate as the cases per 100,000 people (workflow step 2).
Convert the COVID data to a non-geographic data frame.

```{r covid-rate}
covid_table <- covid %>%
  mutate(covid_rate = round(covid$cases / covid$pop * 100000, 2)) %>%
  st_drop_geometry()                                                            #This line converts to a non-geographic data frame?  Why do we need to do this?
```

Join dependent COVID data to independent ACS demographic data.

```{r join-covid-to-acs}
# Join COVID incidence rate data to acs data                                    #Joins covid_table to acs_derived --> acs_covid
acs_covid <- acs_derived %>%
  left_join(covid_table, by = "fips")

# move covid_rate column prior to disability percentages
acs_covid <- acs_covid %>%
  select(fips, statefp, county, county_st, covid_rate, everything())
   
rm(acs, acs_derived, covid)                                                     #This removes the inputs/intermediary data tables from our environment
```

## Missing data

**Unplanned deviation for reproduction**: There is one county with missing disability and poverty data.
This was not mentioned in the original study or in our pre-analyis plan.
However, we replace the missing data with zeros, producing results identical to Chakraborty's.
I assert that it is valid to substitute 0 for this missing poverty value, considering that the data might have been suppressed due to low counts.
Removing the county from the analysis is also a justifiable approach, as long as it is similarly excluded from other data inputs.

```{r missing data}
# county with missing data
missing_data_county <- acs_covid %>% 
  filter(is.na(bpov_pct)) %>%
  st_drop_geometry()                    #Identify the county with N/A data     

transposed_data <- as.data.frame(t(missing_data_county))

kable(transposed_data, format = "html", row.names = TRUE, col.names = "Missing County") %>%
  kable_styling(full_width = FALSE) %>%
  row_spec(0, bold = TRUE)

# replace NA with 0 for missing data
acs_covid[is.na(acs_covid$bpov_pct), ]$bpov_pct <- 0
acs_covid[is.na(acs_covid$apov_pct), ]$apov_pct <- 0
```

## Map COVID-19 incidence

Map the county level distribution of COVID-19 incidence rates, comparing to Figure 1 of the original study.

```{r map-covid-rates, message = FALSE}
tm_covid_rates <- tm_shape(acs_covid) +
  tm_polygons("covid_rate",
    title = "COVID-19 Cases per 100,000 people\n(22 January 2020 to 1 August 2020)",
    style = "quantile",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Oranges",
  ) +
  tm_shape(state) +
    tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_covid_rates
```

## Map disability rates

**Unplanned deviation for reproduction**: We also map the spatial distribution of the percent of people with any disability to improve our understanding of the geographic patterns and relationships of between the overarching independent variable (percentage of people with disability) and the dependent variable (COVID-19 incidence rate).

```{r map-disability-rates, message = FALSE}
tm_disability_rates <- tm_shape(acs_covid) +
  tm_polygons("dis_pct",
    title = "Percent of People with Disability\n(ACS 2014-2018)",
    style = "quantile",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Oranges"
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_disability_rates
```

## Descriptive statistics

Calculate descriptive statistics for dependent COVID-19 rate and independent socio-demographic characteristics, reproducing the min, max, mean, and SD columns of original study table 1.

**Planned deviation for reanalysis**: We also calculate the Shapiro Wilk test for normality.

```{r descriptive-statistics}
acs_covid_stats <- acs_covid %>%
  st_drop_geometry() %>%
  select(covid_rate, contains("pct")) %>%                                       #Selects all the generated PwD subgroup variable columns
  stat.desc(norm = TRUE) %>%
  round(2) %>%
  t() %>%                                                                       #What does t() do?
  as.data.frame() %>%
  select(min, max, mean, SD = std.dev, ShapiroWilk = normtest.W, p = normtest.p)#Selects all the summary statistics for table

acs_covid_stats %>%
  kable(caption = "Reproduced Descriptive Statistics",                          #Generates Table 1
        align = "c") %>%
  column_spec(2:6, width_min = "5em") %>%
  column_spec(7, width_min = "2em") %>%
  kable_styling(full_width = FALSE)
```

Compare reproduced descriptive statistics to original descriptive statistics.
Difference is calculated as 'reproduction study - original study'.
Identical results will result in zero.

```{r compare-descriptive-stats}
# load original table 1 results
table1 <- read.csv(here("data", "raw", "public", "chakraborty", "table1.csv"))

# subtract original results from reproduced results
(select(acs_covid_stats, min, max, mean, SD) -
  select(table1, min, max, mean, SD)) %>%
  kable(caption = "Descriptive Statistics Comparison",
        align = "c") %>%
  column_spec(2:5, width = "4em") %>%
  kable_styling(full_width = FALSE)

rm(acs_covid_stats)
```

The descriptive statistics are identical, except that the original study seems to have rounded the COVID-19 statistics to zero decimal places.
**Great point here**

# Analytical methods

## Bivariate parametric correlation analysis

The county-level Pearson's rho correlation coefficient was used to test association between intra-categorical rates of disability and COVID-19 incidence rates.
As this was a parametric test, normality should be tested.
A separate hypothesis was formulated for disability in aggregate and for each sociodemographic disability characteristic.

Calculate Pearson's R Correlation Coefficient of each independent variable and the COVID-19 incidence rate, reproducing the Pearson's R column of original study Table 1.

```{r pearsons-correlation}
df <- sum(!is.na(acs_covid$dis_pct)) - 2

pearsons_r <- acs_covid %>%
  select(where(is.numeric)) %>%
  st_drop_geometry() %>%
  cor(method = "pearson", use = "everything") %>%
  as.data.frame() %>%
  select(r = covid_rate) %>%
  mutate(
    t = abs(r) / sqrt((1 - r^2) / (df)),
    p = pt(t, df, lower.tail = FALSE)
  ) %>%
  round(3) %>%
  rownames_to_column("variable") %>%
  filter(variable != "covid_rate")

pearsons_r %>%
  kable(caption = "Reproduced Pearson's R",
        align = "c") %>%
  column_spec(2:4, width = "4em") %>%
  kable_styling(full_width = FALSE)
```

Compare the reproduced Pearson's *r* correlation coefficients to the original study's Pearson's *r* correlation coefficients.
Stars indicates the significance level with two stars for `p < 0.01` and one star for `p < 0.05`.
Correlation difference `rp_r_diff` is calculated between the reproduction study `rp_r` and original study `or_r` as `rp_r_diff = rp_r - or_r` Direction difference `rp_dir_diff` is calculated as `(rp_r > 0) - (or_r > 0)`, giving `0` if both coefficients have the same direction, `1` if the reproduction is positive and the original is negative, and `-1` if the reproduction is negative but the original is positive.

**I AM CONFUSED HERE**

```{r compare-pearsons-correlation}
# calculate number of significance stars at p < 0.01 and p < 0.05 levels.
pearsons_r <- mutate(pearsons_r, rp_stars = as.numeric(as.character(cut(p,
  breaks = c(-0.1, 0.01, 0.05, 1),
  labels = c(2, 1, 0)
))))

# join reproduction coefficients to original study coefficients
correlations <- table1 %>%
  filter(variable != "covid_rate") %>%
  select(variable, or_r = r, or_stars = stars) %>%
  left_join(select(pearsons_r, variable, rp_r = r, rp_stars), by = "variable")

# find difference between coefficient and stars
correlations <- correlations %>%
  bind_cols(rename_with(
    correlations[, 4:5] - correlations[, 2:3],
    ~ paste0(.x, "_diff")
  ))

# find coefficients with different directions
correlations <- correlations %>% mutate(rp_dir_diff = (rp_r > 0) - (or_r > 0))

correlations %>%
  kable(caption = "Compare reproduced and original Pearson's R",
        col.names = c("Variable", "R", "Sig. Level", "R", "Sig. Level", "R", "Sig. Level", "Direction"),
        align = "c") %>%
  kable_styling() %>%
  add_header_above(c(" " = 1, "Original" = 2, "Reproduced" = 2, "Difference" = 3))
```

Reproduction correlation coefficients varied slightly from the original study coefficients by +/- 0.006.
All but one Pearson's correlation coefficient was significant to the same level, and the exception was age 18 to 34.
Counter-intuitively, the correlation coefficient was slightly closer to 0 but the *p* value was also found to be more significant, suggesting a difference in the estimation of *t* and/or *p*, or a typographical error.
All of the coefficients had the same direction.

**Unplanned Deviation for Reproduction**: We should expect identical results for this correlation test, so we loaded the original author's data from `Aug1GEEdata.csv` to re-test the statistic, calculated as `unplanned_r` below.

```{r original-data-pearson-correlation}
# load author-provided original data
original_gee <- read.csv(here("data", "raw", "public", "chakraborty", "Aug1GEEdata.csv"))

# calculate correlation coefficients using original data
original_gee %>%
  select(Incidence, PerDisable, starts_with("PD")) %>%
  cor(method = "pearson", use = "everything") %>%
  as.data.frame() %>%
  rownames_to_column("or_variable") %>%
  filter(or_variable != "Incidence") %>%
  select(or_variable, unplanned_r = Incidence) %>%
  bind_cols(correlations[, 1:2]) %>%
  mutate(unplanned_r = round(unplanned_r, 3), diff = unplanned_r - or_r) %>%
  select(variable, unplanned_r, or_r, diff) %>%
  kable(caption = "Recalculation of Pearson's R with original data",
        align = "c",
        ) %>%
  kable_styling(full_width = FALSE)
```

The author's original data produced coefficients identical to the original publication!
Is it possible that the data values are correct but have been reassigned / transposed to different counties?

*Unplanned Deviation for Reproduction*: Considering the precise bitwise reproduction of descriptive statistics and of correlation statistics from author-provided data, we decided to recalculate the COVID-19 incidence rate with author-provided case and population data for comparison to the author-provided incidence rate.

```{r compare-incidence-rate}
# recalculate Incidence Rate
original_gee <- original_gee %>%
  mutate(recalc_Incidence = round(Cases / Total_POP * 100000, 2))

# compare recalculation to author-provided original data and print any counties
# with inconsistent results
original_gee %>%
  filter(recalc_Incidence != Incidence) %>%
  select(FIPS = COUNTY_FIPS, State = ST_Name, County = Countyname, Population = Total_POP, Cases, OR_Incidence = Incidence, RPr_Incidence = recalc_Incidence) %>%
  mutate(Difference = RPr_Incidence - OR_Incidence) %>%
  kable(caption = "Counties with inconsistent COVID-19 incidence rate") %>%
  kable_styling(latex_options = "scale_down")
```

We found that 13 counties had incorrect COVID-19 incidence scores, and the scores seem to be transposed from other counties, such that the overall descriptive statistics were accurate but the correlation coefficients were inaccurate.
This finding implies that subsequent analyses using the COVID-19 Incidence rate will be slightly different and more accurate in this reproduction study than in the original study.
**WOW, CRAZY THAT THE INCIDENCE SCORES WERE INCORRECT. HOW DID YOU THINK TO CHECK?**

**Unplanned deviation for reproduction:** Join the original author's Incidence data into our reproduction data frame so that we can later test for sensitivity to this error.
Then report any counties for which the reproduced COVID incidence rate differs from the original author's COVID incidence rate.

```{r join-incidence-rate}
original_incidence <- original_gee %>%
  select(COUNTY_FIPS, or_incidence = Incidence) %>%
  mutate(fips =
           ifelse(COUNTY_FIPS >= 10000,
                  as.character(COUNTY_FIPS),
                  paste0("0", COUNTY_FIPS)
                  )
         )
  # calculates a text version of FIPS code for joining, while adding back
  # the leading '0' if the code was less than 10000

acs_covid <- acs_covid %>%
  left_join(original_incidence, by = "fips")

rm(original_incidence)

acs_covid %>%
  st_drop_geometry %>%
  filter(covid_rate != or_incidence) %>%
  arrange(fips) %>%
  select(county_st, covid_rate, or_incidence) %>%
  kable(caption = "Original incidence rate joined to reproduction data") %>% kable_styling()
```

The join worked, highlighting the same 13 counties with inconsistent incidence rates.
This also confirms that our reproduced dependent variable is identical to the original dependent variable with the exception of these three counties.

## Bivariate nonparametric correlation analysis

**Unplanned Deviation for Reproduction**: The dependent and independent variables in this study do not have normal distributions, as shown in the Shapiro-Wilk test results above.
Therefore, we deviate from the original study to use the Spearman's Rho non-parametric correlation test.

```{r spearmans correlation}
df <- sum(!is.na(acs_covid$dis_pct)) - 2

spearmans_rho <- acs_covid %>%
  select(where(is.numeric)) %>%
  st_drop_geometry() %>%
  cor(method = "spearman", use = "everything") %>%
  as.data.frame() %>%
  select(rho = covid_rate) %>%
  mutate(
    t = abs(rho) / sqrt((1 - rho^2) / (df)),
    p = pt(t, df, lower.tail = FALSE)
  ) %>%
  round(3) %>%
  rownames_to_column("variable") %>%
  filter(variable != "covid_rate")
```

Compare the Spearman's *rho* correlation coefficients to the reproduced Pearson's *r* correlation coefficients.
Differences are calculated as *Spearman's Rho* - *Pearson's R*.

```{r compare-spearmans-correlation}
# calculate number of significance stars at p<0.01 and P<0.05 levels.
spearmans_rho <- mutate(spearmans_rho, rp_rho_stars = as.numeric(as.character(cut(p,
  breaks = c(-0.1, 0.01, 0.05, 1),
  labels = c(2, 1, 0)
))))

correlations <- correlations[, 1:8] %>%
  left_join(select(spearmans_rho, variable, rp_rho = rho, rp_rho_stars), by = "variable")

corrdiff <- select(correlations, starts_with("rp_rho")) -
  select(correlations, rp_r, rp_stars)

correlations <- correlations %>% bind_cols(rename_with(corrdiff, ~ paste0(.x, "_diff")))
rm(corrdiff)

correlations <- correlations %>% mutate(rp_rho_dir_diff = (rp_rho > 0) - (rp_r > 0))

correlations %>%
  select(variable, rp_r, rp_stars, starts_with("rp_rho")) %>%
  kable(col.names = c("Variable", "R", "Stars", "Rho", "Stars", "Rho - R", "Stars", "Direction"),
        align = "c") %>%
  #column_spec(2:6, width_min = "5em") %>%
  kable_styling() %>%
  add_header_above(c(" " = 1, "Pearson's" = 2, "Spearman's" = 2, "Difference" = 3))
```

Three variables change significance levels, with *Native American* and *Other* races gaining significance and *age 18-34* losing significance.
Two correlations change direction, with both *Native American* race (illustrated in scatterplot below) and *Female* households switching from positive correlations to negative correlations.
Instabilities between the parametric and non-parametic correlations arise from variables with very skewed distributions and/or weak correlations at the county level.
Some difference may also be attributable to the 13 counties with data errors in the COVID-19 Incidence Rate.
In such distributions, outlier observations have more weight in the parametric Person's R test than in the non-parametric Spearman's Rho test.

```{r plot-bivariate, fig.width=4, fig.height=4}
plot(acs_covid$native_pct,
  acs_covid$covid_rate,
  xlab = "Percent Native American",
  ylab = "COVID-19 Incidence",
  pch = 16,
  col = rgb(0, 0, 0, 0.05),
  cex.lab = 0.8,
  cex.axis = 0.5,
)
lines(abline(lm(acs_covid$covid_rate ~ acs_covid$native_pct)))

rm(spearmans_rho, pearsons_r, correlations, table1, df)
```

## Kulldorff spatial scan statistic

Although there were no major geographic *transformations* in this study, *geographic grouping criteria* for the generalized estimating equation (GEE) models are defined as a combination of states and COVID-19 risk, which is based on the Kulldorff spatial scan statistic for geographic clusters of high COVID-19 incidence.
The scan statistic in SaTScan used spherical great circle distance calculations based upon the latitude and longitude coordinates of the centroid of each county.
For this purpose, we have used the `X` and `Y` attributes provided as geographic variables with ACS data.

We use a Kulldorff spatial scan statistic to detect spatial clusters of high COVID-19 incidence (workflow step 6).
The statistic uses a Monte Carlo simulation to calculate statistical significance, and therefore may not produce identical results each time.

The original study uses SaTScan software to implement the Kulldorff spatial scan statistic model.
In SaTScan, models may be specified with many parameters having significant implications for results.
The original manuscript only specifies that Poisson model should be used.
We can also intuit that the model is discrete (locations are stationary and non-random), and spatial only (there is no temporal dimension).
The author-provided SaTScan results `SatScan_results.txt` contains additional parameters which appear to adhere closely to the software's default settings.
These include the maximum cluster size of "50 percent of population at risk", and the "GINI optimized cluster collection" and "no geographical overlap" options for detecting secondary clusters.
The "P-value Cutoff" for significant clusters option did not appear in the v9.6 output, suggesting that the software only allowed the default "no" option for this at the time of the original study.

SaTScan software can also output two versions of geographic data:

-   The `col` cluster polygon shapefile contains a circle for each cluster, where each polygon is a circle defined by the cluster center and radius. The attributes include a variable `REL_RISK` for cluster relative risk
-   The `gis` location point shapefile contains one point for each county in a cluster. The attributes include variables `LOC_RR` for local relative risk and `CLU_RR` for cluster relative risk

The SaTScan software implementation of the Kulldorff spatial scan statistic calculates two relative risk scores for locations:

-   Cluster relative risk is the incidence rate of the population within the cluster divided by the incidence rate of the population outside of the cluster. This is calculated as `REL_RISK` in the `col` cluster polygon shapefile and as `CLU_RR` in the `gis` location point shapefile.
-   Local relative risk is the incidence rate of population within a location divided by the incidence rate of the population outside of the location. This is calculated as `LOC_RR` in the `gis` location shapefile, and is not calculated in the `col` cluster polygon shapefile.

For the purposes of interpreting the spatial scan statistic, a *location* is a *county centroid* while a *cluster* is a *collection of counties* with high incidence rates, defined in the shape of a circle with a *center* location (a county centroid) and a *radius*.

The original study is not clear about using the cluster geographic data *vs* the location geographic data or the cluster relative risk *vs* local relative risk.
However, The author-provided `SatScan_results.txt` results file indicates a geographic cluster file but no location file, and the author-provided `Aug1GEEdata.csv` data table contains a `REL_RISK` field but no `CLU_RR` field or `LOC_RR` field.
This suggests that in the original study, the `col` polygon cluster shapefile and *cluster* relative risk were used to represent COVID-19 risk and define GEE clusters.

The spatial scan statistic is based on case counts and total population, and is therefore unaffected by errors in the COVID Incidence rate.

**Planned deviation for reproduction**: We opted to use the SpatialEpi package in R, selecting open source software with R integration over SatSCan software, which is free but not open.
The Kulldorff spatial scan statistic model in SpatialEpi also supports a discrete Poisson spatial model, and uses the GINI coefficient to select secondary clusters with no geographical overlap that maximize the difference between locations inside of clusters and locations outside of clusters.
We expected that this set of software options could reproduce identical results compared to SaTScan.

First, calculate the Kulldorff spatial scan statistic using SpatialEpi.
Optionally, skip this code block due to long run times of more than 10 minutes.

```{r SpatialEpi-Kulldorff, eval = FALSE, fig.width=4, fig.height=4}
start_time <- Sys.time()
covid_geo <- covid_table %>%
  select(x, y) %>%
  latlong2grid()
# latlong2grid creates approximate equidistant cylindrical grid
# could probably reproject to epsg 5070 and create table with x and y

# calculate expected cases with one strata
expected.cases <- expected(covid_table$pop, covid_table$cases, 1)

# Kulldorff spatial scan statistic                                        ####I CANNOT GET THIS TO RUN
covid_kulldorff <- kulldorff(
  geo = covid_geo,
  cases = covid_table$cases,
  population = covid_table$pop,
  expected.cases = expected.cases,
  pop.upper.bound = 0.5,
  n.simulations = 999,
  alpha.level = 0.05,
  plot = TRUE
)

print(
  paste(
    "Run time:",
    round(difftime(Sys.time(), start_time, units = "mins"), 2),
    "minutes"
  ),
  quote = FALSE
)
rm(covid_geo, expected.cases, start_time)

# save results in a file appended with the current date
saveRDS(covid_kulldorff,
  file = here("data", "derived", "public", paste0("covid_kulldorff_", Sys.Date(), ".RDS"))
)
```

Load pre-calculated Kulldorff spatial scan results.
Alternatively, skip or modify this code block to use your own version of the SpatialEpi Kulldorff results.

```{r load-Kulldorff}
# load pre-calculated Kulldorff results
# alternatively, modify the file name with an appended date to load a more current set of results
covid_kulldorff <- readRDS(
  here("data", "derived", "public", "covid_kulldorff.RDS")
)
```

Report Kulldorff spatial scan results.

```{r report-Kulldorff}
print("Most likely cluster:", quote = FALSE)
covid_kulldorff$most.likely.cluster
print(
  paste0(
    "Number of Secondary clusters: ",
    length(covid_kulldorff$secondary.clusters)
  ),
  quote = FALSE
)
```

The `SpatialEpi` implementation of Kulldorff spatial scan statistics provides output in the form of hierarchical lists analogous to the text output of SaTScan, but does not output a simple data frame or tabular output analogous to the shapefiles from SaTScan.
Therefore, additional steps are required to append the Kulldorff scan results to the `acs_covid` simple features data frame.
This can be done by assigning unique cluster ID's to each county within a cluster.
Clusters include the county at the center of a cluster and all of the other counties within the cluster radius.
Therefore, we use the FIPS code of the county at the center of each cluster as the unique cluster ID.

```{r assign-cluster-IDs, message = FALSE}
# list of primary cluster locations (counties)
cluster_locations <- covid_kulldorff$most.likely.cluster$location.IDs.included

# create data frame of clusters and
# calculate the clusterID as the first (center) county FIPS code
clusters <- covid_table[cluster_locations, "fips"] %>%
  mutate(clusterID = covid_table[[cluster_locations[1], "fips"]],
         likelihood = covid_kulldorff$most.likely.cluster$log.likelihood.ratio)

# Get a list of secondary clusters
secondary <- covid_kulldorff$secondary.clusters

# similarly add counties in each secondary cluster to the list of clusters
for (i in secondary) {
  cluster_locations <- i$location.IDs.included
  new_clusters <- covid_table[cluster_locations, "fips"] %>%
    mutate(clusterID = covid_table[[cluster_locations[1], "fips"]],
           likelihood = i$log.likelihood.ratio)
  clusters <- clusters %>% rbind(new_clusters)
}

rm(cluster_locations, secondary, i, new_clusters)
```

### Map Kulldorff clusters

**Unplanned deviation for reproduction**: The original study does not include visualizations of the spatial structure and distribution of COVID-19 clusters.

First, we must join the Kulldorff spatial scan cluster IDs to the acs_covid simple features dataframe.
Although this was planned in workflow step 9, the order of operations between steps 9 and steps 7 and 8 is not important.

Next, calculate a new field `isCluster` to identify counties in COVID-19 clusters.
Additionally, distinguish between counties defining the center of a cluster from counties constituting other parts of a cluster by comparing the cluster ID (equivalent to the center county's fips code) to the county fips code.

```{r join-clusterID-to-acs_covid}
acs_covid <- acs_covid[, 1:which(colnames(acs_covid) == "or_incidence")] %>%
  left_join(clusters, by = "fips") %>%
  mutate(isCluster = case_when(
    clusterID == fips ~ "center of cluster",
    !is.na(clusterID) ~ "other part of cluster",
    .default = NA
  ))
```

**Planned deviation for reproduction**: Map the `SpatialEpi` cluster results.

```{r map-clusters}
tm_spatialepi_clusters <-
  tm_shape(state) +
    tm_fill("gray98") +
  tm_shape(acs_covid) +
  tm_polygons(col = "isCluster",
          palette = "-Oranges",
          popup.vars = c("fips", "clusterID"),
          colorNA = NULL,
          title = "SpatialEpi Kulldorff COVID-19 Clusters",
          border.col = "white",
          lwd = 0.2,
          border.alpha = 0.2) +
  tm_shape(state) +
    tm_borders("grey", lwd = 0.5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_clusters
```

**Unplanned deviation for reproduction**: The `SpatialEpi` implementation of Kulldorff spatial scan statistics does not calculate local relative risk or cluster relative risk.
Therefore, the next step is to calculate local and cluster relative risk (workflow step 7).

```{r relative-risk}
total_pop <- sum(acs_covid$pop)
total_cases <- sum(acs_covid$cases)

acs_covid <- acs_covid %>%
  group_by(clusterID) %>%
  mutate(
    rr_cluster = ifelse(is.na(clusterID), NA,
      (sum(cases) / sum(pop)) / ((total_cases - sum(cases)) / (total_pop - sum(pop)))
    )
  ) %>%
  ungroup() %>%
  mutate(
    rr_loc = (cases / pop) / ((total_cases - cases) / (total_pop - pop))
  )

rm(total_pop, total_cases)
```

Classify relative risk on a scale from 1 to 6 (workflow step 8).
Risk is classified according to this table:

| Relative Risk Values | Relative Risk Class |
|:--------------------:|:-------------------:|
|  Outside of cluster  |          1          |
|       RR \< 1        |          1          |
|    1 \<= RR \< 2     |          2          |
|    2 \<= RR \< 3     |          3          |
|    3 \<= RR \< 4     |          4          |
|    4 \<= RR \< 5     |          5          |
|    5 \<= RR \< 6     |          6          |

Counties falling outside of any cluster are assigned a score of 1.

```{r classify-relative-risk}
# class breaks
breaks <- c(-Inf, 1, 2, 3, 4, 5, Inf)

acs_covid <- acs_covid %>%
  mutate(
    cluster_class = ifelse(is.na(clusterID), 1, cut(rr_cluster, breaks, labels = FALSE)), #cluster RR based on Spatial Epi Kuldorff
    loc_class = cut(rr_loc, breaks, labels = FALSE) #local RR based on Spatial Epi Kulddorff
  )
```

### Map relative risk scores

**Unplanned deviation for reproduction**: It would be helpful to visualize the spatial distributions of local relative risk classes and Kulldorff cluster relative risk classes in advance of using these classes to control for spatial heterogeneity in GEE models.

First, map the spatial distribution of local relative risk score classifications.

```{r map local relative risk score}
# count the frequency of counties in each class and create labels
class_freq <- acs_covid %>% st_drop_geometry() %>% count(loc_class)
class_freq$qual <- ifelse(class_freq$n > 1, " counties", " county")
class_freq[1, ]$qual <- paste(class_freq[1, ]$qual, "at low risk")
class_freq[nrow(class_freq), ]$qual <- paste(class_freq[nrow(class_freq), ]$qual, "at high risk")
class_freq$label <- paste0(class_freq$loc_class,
                           " (",
                           class_freq$n,
                           class_freq$qual,
                           ")")

# Map Local Relative Risk scores
tm_spatialepi_local_risk_class <- tm_shape(acs_covid) +
  tm_polygons("loc_class",
    title = "Local Relative Risk Class",
    border.col = "white",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Oranges",
    style = "cat",
    labels = class_freq$label
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

rm(class_freq)

tm_spatialepi_local_risk_class
```

Next, map the cluster relative risk scores for comparison.
Note that following the original study classification methodology, counties outside of clusters are assigned the lowest risk class of `1`.

```{r map-cluster-relative-risk-classes}
# count the frequency of counties in each class and create labels
class_freq <- acs_covid %>% st_drop_geometry() %>% count(cluster_class)
class_freq$qual <- ifelse(class_freq$n > 1, " counties", " county")
class_freq[1, ]$qual <- paste(class_freq[1, ]$qual, "at low risk")
class_freq[nrow(class_freq), ]$qual <- paste(class_freq[nrow(class_freq), ]$qual, "at high risk")
class_freq$label <- paste0(class_freq$cluster_class,
                           " (",
                           class_freq$n,
                           class_freq$qual,
                           ")")

# map cluster relative risk scores
tm_spatialepi_cluster_risk_class <- tm_shape(acs_covid) +
  tm_polygons("cluster_class",
    title = "Cluster Relative Risk Class",
    border.col = "white",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Oranges",
    style = "cat",
    labels = class_freq$label
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

rm(class_freq)

tm_spatialepi_cluster_risk_class
```

Comparing the cluster and local relative risk classifications for regions like the Southeast, it is apparent that some areas of high risk are represented with large clusters that have an averaging effect on the cluster-based relative risk score.
This effect is more pronounced for clusters with low compactness (e.g. the Southeast cluster stretched over the "black belt" region from Louisiana and Arkansas to Georgia) than clusters with higher compactness (e.g. New York City) because the circular shape of clusters includes more low-risk counties.

### Compare clusters

The original study did not directly report any results from the Kulldorff spatial scan statistic.
However, the Kulldorff cluster relative risk scores were combined with states to create clusters for GEE models, hereafter called "GEE clusters".
The original study reported `102` unique GEE clusters having a range of `1` to `245` counties in each cluster.

In order to compare results, we first create cluster IDs as combinations of the state ID and COVID relative risk class.
The first clustering ID (State) and second clustering score (COVID relative risk class) were combined to form IDs for each unique combination of state and relative risk class.
Then, we find the number of unique clusters and frequency counties per cluster in our reproduction study for comparison to the original study.

```{r make-gee-clusters}
# calculate clusters
acs_covid <- acs_covid %>% mutate(
  rp_clusID = as.integer(statefp) * 10 + cluster_class
)

# summarize clustering results
cluster_summary <- acs_covid %>%
  filter(cases > 0) %>%
  st_drop_geometry() %>%
  count(rp_clusID)
cat(
  length(cluster_summary$n),
  "unique clusters based on spatialEpi CLUSTER relative risk\n"
)
summary(cluster_summary$n)
rm(cluster_summary)
```

We failed to reproduce the same configuration of GEE clusters as the original study, finding 9 more clusters than the original study and a much smaller maximum cluster of 159 counties compared to 245 counties.

### Reproduce Kulldorff spatial scan statistic in SaTScan

**Unplanned deviation for reproduction**: Upon failing to reproduce an identical number of GEE clusters using SpatialEpi in R, we reproduced the procedure in the free but not open SaTScan software, using the current software version 10.1.
The input data files (`case`, `Coordinates.geo`, and `Population.pop`), and output data files (`sat_scan_rpr.txt`, `sat_scan_rpr.col.shp`, and `sat_scan_rpr.gis.shp`) are found in the `data/derived/public/satscan` directory.
The `sat_scan_rpr.txt` file reports the model parameters used in addition to results.

Although it is not ideal to intercede with this unplanned deviation at this step, is the first step in the methodology following the Kulldorff spatial scan statistic with a result reported in the original publication.

First, load and verify whether our SaTScan reproduction data compares to the author-provided SaTScan data.

```{r load-satscan-col}
# load author-provided data
author_col <- read.dbf(here("data", "raw", "public", "chakraborty", "SatScan_output.dbf")) %>%
  select(LOC_ID, or_rel_risk = REL_RISK)

# load SaTScan reproduced data
satscan_rpr_col <- read_sf(here("data", "derived", "public", "satscan", "sat_scan_rpr.col.shp"))

# how many observations?
cat(
  nrow(satscan_rpr_col),
  " reproduced relative risk observations\n",
  nrow(author_col),
  " author-provided relative risk observations\n",
  sep = ""
)

# join and compare how many observations are identical?
cat(
  satscan_rpr_col %>%
  full_join(author_col, by = "LOC_ID") %>%
  filter(REL_RISK == or_rel_risk & REL_RISK > 0) %>%
  nrow(),
  "reproduced relative risk values match the original author's relative risk values"
  )

rm(author_col)
```

Our SaTScan results exactly reproduced the author-provided SaTScan results data.

#### Map SaTScan spatial clusters

Join the SaTScan results to `acs_covid` for mapping and analysis.

```{r join-satscan-to-acs-covid}
# check if there are any duplicated counties
cat("Joining",
    length(satscan_rpr_col$LOC_ID),
    "records with",
    length(unique(satscan_rpr_col$LOC_ID)),
    "unique LOC_ID county values")

# select important non-geographic columns
satscan_rpr_col_t <- satscan_rpr_col %>%
  st_drop_geometry() %>%
  select(fips = LOC_ID, GINI_CLUST, REL_RISK)

# join
acs_covid <- acs_covid[, 1:which(colnames(acs_covid) == "rp_clusID")] %>%
  left_join(satscan_rpr_col_t, by = "fips")

rm(satscan_rpr_col_t)
```

**Unplanned deviation for reproduction**: Visualize the spatial distribution of the author-provided Kulldorff COVID-19 Clusters.

```{r map--author-clusters}
# count frequencies of each cluster type
clus_counts <- satscan_rpr_col %>%
  st_drop_geometry() %>%
  group_by(GINI_CLUST) %>%
  summarize(n = n())

# create labels including frequencies in brackets
clus_labels <- c(paste0("Hierarchical (", clus_counts[1,2], ")"),
            paste0("GINI Optimized (", clus_counts[2,2], ")"))

# for clusters with only one county, erase the number of counties
satscan_rpr_col[which(satscan_rpr_col$NUMBER_LOC < 3), ]$NUMBER_LOC <- NA

gini_circle <- satscan_rpr_col %>% filter(GINI_CLUST == 'T')
hier_circle <- satscan_rpr_col %>% filter(GINI_CLUST == 'F')

tm_author_clusters <-
  tm_shape(state) +
    tm_fill("gray98") +
  tm_shape(acs_covid) +
  tm_polygons(col = "GINI_CLUST",
              labels = clus_labels,
              border.col = "white",
              lwd = 0.5,
              palette = c("tomato", "thistle3"),
              popup.vars = c("fips", "clusterID"),
              colorNA = NULL,
              title = "SaTScan Kulldorff COVID-19 Clusters\nCluster Centers") +
  tm_shape(state) +
    tm_borders("grey", lwd = 0.5) +
  tm_shape(gini_circle) +
    tm_borders(col = "thistle4") +
    tm_text("NUMBER_LOC", size = 0.5) +
  tm_shape(hier_circle) +
    tm_borders(col = "tomato") +
    tm_text("NUMBER_LOC", size = 0.5, ymod = 0.4) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  ) +
  tm_add_legend('symbol',
              	col = NA,
              	border.col = c("tomato", "thistle4"),
              	size = 0.7,
              	labels = clus_labels,
              	title="Cluster Extents")

tm_author_clusters

rm(gini_circle, hier_circle, clus_counts, clus_labels)
```

In the map above, clusters containing only one county have no visible circle.
Clusters containing two counties are encircled, but have no label.
Clusters containing three or more counties are encircled and labelled with the number of counties.

Note that this version of data only includes the 96 counties defining cluster centers, visualized with fill colors above.
The data excludes all of the non-center counties in clusters with more than one county.
The extent of these larger clusters is visualized by unfilled circles defined by cluster radii.

Additionally, the SaTScan software confusingly merges two sets of clusters in the results when the user uses the (default) option for GINI-optimized clusters.
One set of results is a hierarchical non-overlapping set of clusters.
These clusters are noted with `GINI_CLUST = F` in the results.
The second set of results is a set of hierarchical non-overlapping clusters designed to maximize the GINI coefficient of inequality between counties within clusters and counties outside of clusters.
These clusters are noted with `GINI_CLUST = T` in the results.

Merged together as they are, the two sets of secondary clusters overlap one another geographically, causing ambiguity in terms of which cluster-based relative risk score should be used at each location.

**Unplanned deviation for reproduction**: Can we also use these reproduced SaTScan results to exactly reproduce the author-reported frequency of original GEE classes and maximum counties per class?
If the results match, it will confirm that the problems identified above have propagated through the original study analysis.

```{r reproduce-gee-clusters}
acs_covid <- acs_covid %>%
  mutate(
    ss_cluster_class = ifelse(is.na(REL_RISK), 1, cut(REL_RISK, breaks, labels = FALSE)),
    ss_clusID = as.integer(statefp) * 10 + ss_cluster_class
  )

cluster_summary <- acs_covid %>%
  filter(cases > 0) %>%
  st_drop_geometry() %>%
  count(ss_clusID)
cat(
  length(cluster_summary$n),
  "unique clusters based on spatialEpi CLUSTER relative risk\n"
)
summary(cluster_summary$n)
```

Using SaTScan Kulldorff clusters, we have exactly reproduced the author-reported frequency of original GEE classes and maximum counties per class.
We have confirmed that the original study used the *cluster relative risk* of the *center county* of each cluster, including both the *hierarchical* and *GINI-optimized* sets of clusters.

#### Compare SaTScan clusters to SpatialEpi clusters

**Unplanned Deviation for Reanalysis:** At this point it is clear that the best decision will be to shift from a *reproduction* study to a *reanalysis* study, intentionally altering methodological decisions to achieve a more valid outcome.
We prefer to include *all counties* contained in each cluster, and to use only *one set of non-overlapping clusters*, as produced by the `SpatialEpi` algorithm.

Given the shifting goal, how sensitive is this study to the choice of computational environment for the Kulldorff scan statistics?
To answer this question, we must load the local SaTSCan results inclusive of all counties within clusters, filter the results to focus on the standard hierarchical set of clusters, and compare the spatial distributions of the SaTScan and SpatialEpi results.

```{r join-satscan-clusters-all-counties, message = F}
# load local SaTScan reproduced data
satscan_rpr_gis_t <- read_sf(
  here("data", "derived", "public", "satscan", "sat_scan_rpr.gis.shp")
) %>%
  st_drop_geometry() %>%
  select(fips = LOC_ID, CLU_RR, GINI_CLUST)

# check if there are any duplicated counties
cat("SaTScan combined GIS output has",
    length(satscan_rpr_gis_t$fips),
    "records with",
    length(unique(satscan_rpr_gis_t$fips)),
    "unique county values\n")

satscan_rpr_gini <- satscan_rpr_gis_t %>% filter(GINI_CLUST == "T") %>% select(fips, gini_rr = CLU_RR)
satscan_rpr_hier <- satscan_rpr_gis_t %>% filter(GINI_CLUST == "F") %>% select(fips, hier_rr = CLU_RR)

# check if there are any duplicated counties
cat("SaTScan Hierarchical clusters include",
    length(satscan_rpr_hier$fips),
    "records with",
    length(unique(satscan_rpr_hier$fips)),
    "unique county values\n")

cat("SaTScan GINI-optimized clusters include",
    length(satscan_rpr_gini$fips),
    "records with",
    length(unique(satscan_rpr_gini$fips)),
    "unique county values")

acs_covid <- acs_covid[, 1:which(colnames(acs_covid) == "ss_clusID")] %>%
  left_join(satscan_rpr_gini, by = "fips") %>%
  left_join(satscan_rpr_hier, by = "fips")

rm(satscan_rpr_gis_t, satscan_rpr_gini, satscan_rpr_hier)
```

It was necessary to divide the Hierarchical clusters from the GINI clusters to avoid duplicates and geographic overlap.

Compare the SaTScan Hierarchical clusters to the SpatialEpi clusters.

```{r hierarchical-cluster-comparison-map, message = F}
hier_clusters <- acs_covid %>%
  mutate(xcluster = case_when(
    !is.na(hier_rr) & is.na(isCluster) ~ "SaTScan Hierarchical only",
    !is.na(hier_rr) & !is.na(isCluster) ~ "Both SaTScan and SpatialEpi",
    is.na(hier_rr) & !is.na(isCluster) ~ "SpatialEpi only",
    .default = NA
  )) %>%
  filter(!is.na(xcluster)) %>%
  group_by(xcluster) %>%
  mutate(xn = n()) %>%
  ungroup() %>%
  mutate(xcluster = paste0(xcluster, " (", xn, " counties)"))

tm_spatialepi_hier <-
  tm_shape(state) +
  tm_fill("gray98") +
  tm_shape(hier_clusters) +
  tm_polygons(
    col = "xcluster",
    palette = c("wheat", "tomato", "thistle3"),
    colorNA = NULL,
    title = "SaTScan Hierarchical and SpatialEpi Clusters",
    border.col = "white",
    lwd = 0.2,
    border.alpha = 0.3
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = 0.5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_hier

rm(hier_clusters)
```

The two methods only agree on the definition of the largest clusters in distant regions.
Thereafter, SpatialEpi detects many secondary clusters in the vicinity of the largest ones, while SaTScan detects seven isolated and low-probability counties.

Compare the SaTScan GINI Optimized clusters to the SpatialEpi clusters.

```{r gini-cluster-comparison-map, message = F}
gini_clusters <- acs_covid %>%
  mutate(xcluster = case_when(
    !is.na(gini_rr) & is.na(isCluster) ~ "SaTScan GINI optimized only",
    !is.na(gini_rr) & !is.na(isCluster) ~ "Both SaTScan and SpatialEpi",
    is.na(gini_rr) & !is.na(isCluster) ~ "SpatialEpi only",
    .default = NA
  )) %>%
  filter(!is.na(xcluster)) %>%
  group_by(xcluster) %>%
  mutate(xn = n()) %>%
  ungroup() %>%
  mutate(xcluster = paste0(xcluster, " (", xn, " counties)"))

tm_spatialepi_gini <-
  tm_shape(state) +
  tm_fill("gray98") +
  tm_shape(gini_clusters) +
  tm_polygons(
    col = "xcluster",
    palette = c("wheat", "tomato", "thistle3"),
    colorNA = NULL,
    title = "SaTScan GINI Optimized and SpatialEpi Clusters",
    border.col = "white",
    lwd = 0.2,
    border.alpha = 0.3
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = 0.5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_gini

rm(gini_clusters)
```

There is more agreement overall between SpatialEpi and SaTScan GINI Optimized clusters.
The two algorithms agree the most for smaller and less significant clusters above the 95% confidence threshold.
Because the SaTScan clusters are more limited in size, SaTScan detects several smaller clusters with gaps in place of the largest SpatialEpi clusters.

Keeping in mind that the final analysis uses a classification of cluster relative risk for GEE models, are there important differences between the two results with regard to classification of risk?
We can check by calculating cluster relative risk classes based on the SaTScan GINI clusters, and cross-tabulating with the SpatialEpi risk classes.

```{r compare-spatialepi-satscan}
acs_covid <- acs_covid %>%
  mutate(
    gini_class = ifelse(is.na(gini_rr), 1, cut(gini_rr, breaks, labels = FALSE)),
    gini_clusID = as.integer(statefp) * 10 + gini_class
  )

table(acs_covid$cluster_class, acs_covid$gini_class) %>%
  kable(row.names = TRUE, caption = "COVID-19 Risk Class by County", align = "c") %>%
  column_spec(2:7, width = "3em") %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(2, bold = TRUE) %>%
  add_header_above(c("SpatialEpi" = 1, "SatScan" = 6)) %>%
  kable_styling(full_width = FALSE, row_label_position = "c")
```

Indeed, SpatialEpi has identified more than 300 counties with above normal risk that were not identified by SaTScan.
Meanwhile, SaTScan identified 78 counties with above normal risk that were not identified by SpatialEpi.

The maps and crosstabulation above indicate that there are important differences between the SaTScan and SpatialEpi computational environments for calculating secondary clusters.

We summarize our understanding of the computational differences for default settings below, based on close examination of our software outputs, technical documentation for SaTScan, and the documentation and code repository for SpatialEpi.

|                          |      SaTScan Hierarchical      |            SaTScan GINI            |                  SpatialEpi                  |
|:------------------------:|:------------------------------:|:----------------------------------:|:--------------------------------------------:|
|     possible shapes      |  circle (default) or ellipse   |    circle (default) or ellipse     |                    circle                    |
| possible cluster centers | locations with rates \> normal |   locations with rates \> normal   |                all locations                 |
|   maximum cluster size   |          50% of cases          | varies, not exceeding 50% of cases |              50% of population               |
|  maximum *p* of cluster  |              1.00              |                1.00                |                     0.05                     |
|         distance         |     spherical great circle     |       spherical great circle       | spherical equidistant cylindrical projection |

To further interrogate the differences in sets of secondary clusters, we must understand that theoretically each location (county), may be the center of many different circular clusters defined by different radii, starting with a radius of 0 and the one county at the center, and expanding until the maximum cluster size is reached.

**SaTScan Hierarchical Clusters**

-   Select locations (counties) with above-normal COVID incidence rates
-   For each location, find log-likelihood of all possible cluster sizes (from minimum of 2 cases to maximum of 50% of cases) with *p* \< 1
-   For each location, select the cluster with the maximum log-likelihood, resulting in one possible cluster for each location with above-normal COVID incidence rates
-   Sort the remaining clusters by log-likelihood from greatest to least
-   Select the most likely cluster
-   Select secondary clusters by iterating over the remaining clusters, adding new clusters to the set of secondary clusters if they do not geographically overlap any of the clusters already identified as most likely or secondary (pg 68).

**SaTScan GINI-Optimized Clusters**

-   Follow the same procedure as SaTScan Hierarchical clusters, but iterate the procedure with different maximum cluster sizes. By default the cluster sizes include 1, 2, 3, 4, 5, 6, 8, 10, 12, 15, 20, 25, 30, 35, 40, 45, and 50 percent of cases. With the default setting, the result is 17 different sets of clusters.
-   For each set of clusters, calculate the GINI coefficient of the COVID-19 incidence inside the clusters vs outside the clusters.
-   Select the set of clusters with the highest GINI coefficient (i.e. the most difference between COVID-19 incidence inside the clusters vs outside the clusters).

**SpatialEpi Clusters**

-   For all locations, calculate the log likelihood of all the possible clusters below the maximum cluster size (50% of population)
-   Select the clusters with *p* \< 0.05
-   Sort the remaining clusters by log-likelihood from greatest to least (line 186)
-   Select the most likely cluster
-   Select secondary clusters by iterating over the remaining clusters, adding new clusters to the set of secondary clusters if they do not geographically overlap any of the clusters already identified as most likely or secondary (line 199).

The differences between these three approaches have very significant impacts on the results (see the differences in results in the **two maps** above) and it is impossible to control for all of the differences with the available parameters.
Most fundamentally, SaTScan develops sets of secondary clusters from a universe of just one most likely cluster per location with no default limitation its statistical significance, whereas SpatialEpi may consider multiple possible cluster sizes for each location with a default limitation of maximum 0.05 *p* for each cluster.
These fundamental differences are evident in the spatial distribution of clusters.
For example, New York City is the most likely cluster in all analyses.
For counties near New York, the radius of the most likely cluster is large and geographically overlaps New York City.
Therefore, if only the most significant cluster radius is considered as a possible secondary cluster for counties near New York City, all such clusters are disqualified by their geographical overlap.
This is what happens in the SaTScan Hierarchical Clusters model, for which the next nearest clusters are in Ohio and Virginia.
In the SaTScan GINI-optimized model, the maximum cluster size is apparently smaller, such that the most likely cluster in New York City is also smaller.
This change allows for two other non-overlapping secondary clusters in Rhode Island and New Jersey.
In contrast, the SpatialEpi algorithm still considers a variety of possible cluster sizes for each county, allowing for detection of smaller clusters adjacent to more significant ones.

Of course, the *relative risk* score of each cluster is contingent on the cluster size, so each difference in geographic configuration of clusters also impacts the cluster risk classification of individual locations.
The most stable results are for the most likely clusters in distinct regions (New York City, Southeast U.S., Southern California & Nevada), while the most variability appears for secondary clusters close enough for their most likely radius to overlap the more likely clusters.
The circular shape could be considered a major limitation of Kulldorff cluster detection, for which the SaTScan methodology enhances the limitation by constraining the possibility of nearby clusters while the SpatialEpi methodology can detect smaller adjacent secondary clusters.

The high significance threshold in the default SaTScan analysis allows the inclusion of many small clusters with low likelihoods, adding noise to the results.
This could be controlled by overriding the maximum *p* value parameter.
Combining all of the default parameters, SaTSCan includes small clusters of relatively low-risk counties in the Midwest, but excludes relatively high-risk counties adjacent to the major clusters of New York, the Southeast, and Southern California/Nevada.
This problem does not exist in the SpatialEpi implementation, and the SpatialEpi parameter *alpha level* parameter cannot be practically increased to `1` to match the SatSCan default.
This is because SpatialEpi does not filter counties by those with local relative risk greater than 1---therefore an *alpha value* of `1` results in *all* counties being included as clusters.

In sum, there are three construct validity issues with the original study's COVID-19 high-risk clusters as implemented in SaTScan.

1.  Two sets of overlapping secondary clusters are included in the SaTScan output: hierarchical clusters and clusters optimized by GINI coefficient.
2.  Only the 96 counties at the center of a cluster are considered in the risk classification.
3.  The geographic patterns and cluster relative risk scores of secondary clusters are limited to circles or ellipses and are apparently sensitive to both the geographic shape and situation of high-risk clusters and to subjective decisions in parameters and algorithms.

## Preprocess data for GEE modelling

**Unplanned deviation for reanalysis**: Based on the three observations above, we think that it would be more valid to choose one set of secondary clusters based on a single method rather than combining a set of hierarchical clusters with a set of GINI optimized clusters.
We also think that it would be more valid to include risk levels for all counties within a cluster (i.e. all counties within any of the circles above), rather than only the county at the center of a cluster.
Finally, we think it would be more valid to treat clusters as a single category rather than five tiers of above-normal risk.

To complete the reproduction/reanalysis study, we will therefore calculate and compare multiple versions of the GEE models:

1.  Original study results
2.  Original study data in geepack
3.  SpatialEpi cluster classification in geepack
4.  SpatialEpi binary clusters in geepack

### Unique GEE cluster IDs

First, calculate GEE cluster IDs.

We have already calculated: - `rp_clusID` based on our SpatialEpi clusters - `ss_clusID` based on our SaTScan cluster centers, and shown to be identical to the original author's data - `gini_clusID` based on our SaTScan GINI-optimized clusters

### Filter and standardize data

Second, filter the data for non-zero COVID-19 rates and z-score standardize the independent variables.
This accomplishes step 10 of the workflow diagram.

**Unplanned deviation for reproduction:** We assumed that we should filter for COVID rates \> 0 first and then calculate z-scores, however after comparing data in the next code block, we realized that the original study had *first* calculated z-scores and *then* filtered for COVID rates \> 0.
Therefore, to align with the original study, in the next code block we first calculate z-scores and then filter for COVID rates \> 0.

```{r filter-standardize}
gee_data <- acs_covid %>%
# filter(covid_rate > 0) %>% # moved filtering to after z-score calculation
  mutate(
    z_white_pct = scale(white_pct),
    z_black_pct = scale(black_pct),
    z_native_pct = scale(native_pct),
    z_asian_pct = scale(asian_pct),
    z_other_pct = scale(other_pct),
    z_non_hisp_white_pct = scale(non_hisp_white_pct),
    z_hisp_pct = scale(hisp_pct),
    z_non_hisp_non_white_pct = scale(non_hisp_non_white_pct),
    z_bpov_pct = scale(bpov_pct),
    z_apov_pct = scale(apov_pct),
    z_pct_5_17 = scale(pct_5_17),
    z_pct_18_34 = scale(pct_18_34),
    z_pct_35_64 = scale(pct_35_64),
    z_pct_65_74 = scale(pct_65_74),
    z_pct_75 = scale(pct_75),
    z_male_pct = scale(male_pct),
    z_female_pct = scale(female_pct)
  ) %>%  
  filter(covid_rate > 0) # moved filtering from before z-score calculation
```

Compare independent variables for GEE models by subtracting the original values from the reproduced values, and finding the average and standard deviation of difference for each variable.

```{r compare-indp-vars}
# subtract original data matrix (table) from reproduced data matrix (table)
# select, filter, and arrange (sort) data to make identical matrix sizes with
# identical order of observations (counties)
gee_diff <-
  (gee_data %>%
    st_drop_geometry() %>%  
    arrange(as.integer(fips)) %>%
    select(starts_with("z_"))  -
  original_gee %>%
    filter(Cases > 0) %>%
    arrange(COUNTY_FIPS) %>%
    select(starts_with("ZPD"))) %>%
  round(digits = 3)

# I changed this section to report in a table, instead of printing

# calculate mean and sd for the normalize difference values
mean_diff <- colMeans(gee_diff) %>%
  round(digits = 3)

sd_diff <- apply(gee_diff, 2, sd) %>%
  round(digits = 3)

# create a data frame for the table
summary_table <- data.frame(
  Variable = colnames(gee_diff),
  Mean = mean_diff,
  `Standard Deviation` = sd_diff)


kable(summary_table, format = "html", col.names = c("Variable", "Mean", "SD"), align = c("c", "c", "c"), row.names = FALSE,
      caption = "Summary of difference between reproduction independent variables and original independent variables") %>%
  column_spec(1, width_min = "5em") %>%
  column_spec(2, width_min = "5em") %>%
  column_spec(3, width_min = "5em") %>%
  kable_styling(full_width = FALSE, row_label_position = "c")

```

When we had filtered for COVID rates \> 0 first and then z-score standardized second, the means of differences ranged from -0.012 to 0.004, and standard deviations of differences ranged from 0.000 to 0.016.

After changing the order to first z-score standardize and then filter for COVID rates \> 0, we observed no mean difference between our reproduced variables and the original variables, and we find no standard deviation \> 0.001 for the difference between reproduction independent variables and original variables.
There are no major differences between the independent variables.

#### Save final derived data

Optionally, you may save the preprocessed data to `data/raw/public/gee_data.gpkg`

```{r save preprocessed COVID cluster data, eval = FALSE}
write_sf(gee_data, here("data", "derived", "public", "gee_data.gpkg"))
# add saving acs_covid data
```

Optionally, you may load the preprocessed data from `data/raw/public/gee_data.gpkg`

```{r load preprocessed COVID cluster data, eval = FALSE}
gee_data <- read_sf(here("data", "derived", "public", "gee_data.gpkg"))
```

## GEE models

A separate hypothesis was formulated for each type of subcategorization of PwDs, numbered H2.1 through H2.5 in Table 4.

As specified by the author, "GEEs extend the generalized linear model to accommodate clustered data, in addition to relaxing several assumptions of traditional regression (i.e., normality)".
Additionally, the author noted that "clusters of observations must be defined based on the assumption that observations within a cluster are correlated while observations from different clusters are independent." All five GEE models were specified with exchangeable correlation matrices, gamma distributions, and logarithmic link function.
These specifications were chosen after testing each alternative and choosing the models with the best quasilikelihood under the independence model criterion (QIC).

This accomplishes the step 11 of the workflow diagram.

Generalized Estimating Equation parameters:

"The **'exchangeable' correlation matrix** was selected for the results reported here, since this specification yielded the best statistical fit based on the QIC (quasi- likelihood under the independence) model criterion." (Chakraborty 2021, Methods paragraph 5)

"The **gamma distribution** with **logarithmic link function** was chosen for all GEEs since this model specification provided the lowest QIC value." (Chakraborty 2021, Methods paragraph 5)

### Original Table 2

Load digitized version of Table 2 from the original publication.

```{r load-table2}
table2 <- read.csv(here("data", "raw", "public", "chakraborty", "table2.csv"))
table2 <- table2 %>%
  arrange(row_i_first) #%>%
  #column_to_rownames("term")

table2[, 3:ncol(table2)] %>%
  kable(caption = "Original Publication Table 2",
        align = "c") %>%
  kable_styling()
```

### GEE Function

Define a function for calculating and summarizing five GEE models

```{r gee-functions}
onegee <- function(gee_data, dep_var, id, term_names) {

  # sort data frame by clustering variable, a requirement of GEE modeling
  gee_data <- gee_data %>% arrange({{ id }})

  # create list of models and their independent variables
  model_names <- c(
    "race",
    "ethnicity",
    "poverty status",
    "age",
    "biological sex"
  )

  ind_vars <- c(
    "z_white_pct + z_black_pct + z_native_pct + z_asian_pct + z_other_pct",
    "z_non_hisp_white_pct + z_hisp_pct + z_non_hisp_non_white_pct",
    "z_bpov_pct + z_apov_pct",
    "z_pct_5_17 + z_pct_18_34 + z_pct_35_64 + z_pct_65_74 + z_pct_75",
    "z_male_pct + z_female_pct"
  )

  gee_models <- data.frame(model_names, ind_vars)
  gee_model <- list()

  # empty data frame for storing model outputs
  coefficients <- data.frame()
  qics <- data.frame(model_names, qic = c(1:5))

  # run each model and save outputs
  for(i in 1:nrow(gee_models)){

    # run model
    gee_model[[i]] <- geeglm(
      formula = as.formula(paste(dep_var, "~", gee_models[i, "ind_vars"])),
      data = gee_data,
      id = {{ id }}, # cluster IDs
      family = Gamma(link = "log"),
      corstr = "exchangeable",
    )

    # tidy and save variable coefficients, margins of error, significance...
    gee_table <- tidy(gee_model[[i]], conf.int = TRUE)
    gee_table[1, 1] <- paste(gee_models[i, 1], "model intercept")
    coefficients <- coefficients %>% rbind(gee_table)

    # QIC: quasi-likelihood under the independence model information criterion
    QIC(gee_model[[i]])
    qics[i, 2] <- QIC(gee_model[[i]])[1]

    gee_model[[i]]$model <- NA
  }

  # calculate significance levels
  coefficients$stars <- as.numeric(
    as.character(
      cut(coefficients$p.value,
        breaks = c(-0.1, 0.01, 0.05, 1),
        labels = c(2, 1, 0)
      )
    )
  )

  # reorder columns to match table2 in publication and round to 3 sig. digits
  coefficients <- coefficients %>%
    select("estimate", "std.error", starts_with("conf"), "stars", "p.value") %>%
    round(digits = 3)

  # add tidy term names
  coefficients <- bind_cols(term = term_names, coefficients)

  # combine coefficient results and QIC results into a list
  return_data <- list(
    "coefficients" = coefficients,
    "QICs" = qics,
    "models" = gee_model
    )

  return(return_data)
}
```

### Original Clusters and Original COVID-19 Rate

Calculate GEE models with: - Clustering: SaTScan cluster centers & State ID - Dependent variable: original COVID-19 incidence (including errors).

```{r gee-original-clusters-original-incidence}
gee_or_clus_ordep <- gee_data %>% onegee(
                    dep_var = "or_incidence",
                    id = gee_data$ss_clusID,
                    term_names = table2$term)
gee_or_clus_ordep$coefficients %>%
  kable(caption = "Original Cluster IDs and Original COVID-19 Incidence",
        align = "c") %>%
  kable_styling()
```

### Original Clusters and Corrected COVID-19 Rate

Calculate GEE models with: - Clustering: SaTScan cluster centers & State ID - Dependent variable: reproduced COVID-19 incidence (corrected errors).

```{r gee-original-clusters-reproduced-incidence}
gee_or_clus_rpdep <- onegee(gee_data,
                    dep_var = "covid_rate",
                    id = gee_data$ss_clusID,
                    term_names = table2$term)
gee_or_clus_rpdep$coefficients %>%
  kable(caption = "Original Cluster IDs and Reproduced COVID-19 Incidence",
        align = "c") %>%
  kable_styling()
```

### GINI Clusters and Fixed COVID-19 Rate

Calculate GEE models with: - Clustering: Reproduced SaTScan GEE clusters & State ID - Dependent variable: reproduced COVID-19 incidence (fixed errors).

```{r gee-gini-clusters-reproduced-incidence}
gee_gini_clus_rpdep <- onegee(gee_data,
                    dep_var = "covid_rate",
                    id = gee_data$gini_clusID,
                    term_names = table2$term)
gee_gini_clus_rpdep$coefficients %>%
  kable(caption = "Reproduced SaTScan GINI Cluster IDs and Reproduced COVID-19 Incidence",
        align = "c") %>%
  kable_styling()
```

### SpatialEpi Clusters and Fixed COVID-19 Rate

Calculate GEE models with: - Clustering: Reproduced SpatialEpi clusters & State ID - Dependent variable: reproduced COVID-19 incidence (fixed errors).

```{r gee-spatialepi-clusters-reproduced-incidence}
gee_rp_clus_rpdep <- onegee(gee_data,
                    dep_var = "covid_rate",
                    id = gee_data$rp_clusID,
                    term_names = table2$term)
gee_rp_clus_rpdep$coefficients %>%
  kable(caption = "Reproduced SpatialEpi Cluster IDs and Reproduced COVID-19 Incidence",
        align = "c") %>%
  kable_styling()
```

### Planned Addition for Reanalysis: Basic (6) Relative Risk Clusters and Fixed COVID-19 Rate. Cluster Relative Risk Scores - Spatial EPI

Calculate GEE models with: - Clustering: Six Spatial EPI RR Cluster IDs - Dependent variable: fixed COVID-19 incidence (fixed errors).

```{r gee-spatialepi_RR-clusters-corrected-incidence}
gee_spatialepi_RR_clusters <- gee_data %>% onegee(
                    dep_var = "covid_rate",
                    id = gee_data$cluster_class,
                    term_names = table2$term)
gee_spatialepi_RR_clusters$coefficients %>%
  kable(caption = "Basic 6 RR Cluster IDs (from Spatial Epi) and Fixed COVID-19 Incidence",
        align = "c") %>%
  kable_styling()
```

### Planned Addition for Reanalysis: State Clusters and Fixed COVID-19 Rate.

Calculate GEE models with: - Clustering: States - Dependent variable: fixed COVID-19 incidence (fixed errors).

```{r gee-state-clusters-corrected-incidence}
gee_state_clusters <- gee_data %>% onegee(
                    dep_var = "covid_rate",
                    id = gee_data$statefp,
                    term_names = table2$term)
gee_state_clusters$coefficients %>%
  kable(caption = "State Clusters and Fixed COVID-19 Incidence",
        align = "c") %>%
  kable_styling()
```

### Compare GEE results

**Unplanned deviation for reanalysis**: Generate dot-and-whisker plot of coefficients for each of the model variations for efficient visual comparison of coefficients across each model.

```{r dotwhisker-comparison, message=FALSE}
# create summary data frame compatible with dotwhisker package functions
# starting with original study results
t2whisker <- table2 %>%
  mutate(model = "Original Study") %>%
  select(-c(starts_with("row"), "wald_chi_square", "p_stars"))

geewhisker <- bind_rows(
  mutate(gee_or_clus_ordep$coefficients,
         model = "Switch to R Geepack"),
  mutate(gee_or_clus_rpdep$coefficients,
         model = "Correct COVID Incidence"),
  mutate(gee_gini_clus_rpdep$coefficients,
         model = "SaTScan GINI-Optimized Clusters"),
  mutate(gee_rp_clus_rpdep$coefficients,
         model = "SpatialEpi Clusters"),
  mutate(gee_spatialepi_RR_clusters$coefficients,
         model = "Relative Risk Clusters"),
  mutate(gee_state_clusters$coefficients,
         model = "State Fips Cde Clusters")) %>%
  select(1:7, "model")

geewhisker <- bind_rows(t2whisker, geewhisker) %>%
  filter(!grepl("intercept", term))

# generate create dot whisker plot
geewhisker_fig <- geewhisker %>%
  dwplot(dodge_size = 0.6,
         vline = geom_vline(
           xintercept = 0,
           colour = "grey60",
           linetype = 2
       )) +
    scale_colour_brewer(type = "div",
                        palette = "RdYlBu",
                        name = "Model Variations") +
    theme_bw() +
    xlab("Coefficient")

geewhisker_fig

rm(t2whisker)
```

The figure above illustrates seven model variations, starting with the results published in the original study.
The next two models make incremental adjustments to the research design and are most compatible with the goals of a reproduction study.

The greatest differences were produced using the same input data in different computational environments, caused by switching the computational environment from SPSS to geepack in R.
This switch decreased the magnitude of most coefficients, reducing the positive Hispanic coefficient below its original confidence interval and increasing the negative Above poverty level and Male coefficients to the limits of their original confidence intervals.

Compared to the change in computational environment, fixing the error in the COVID-19 incidence rate of 13 counties had very little effect on coefficient estimates.

Our more significant adjustments could be considered reanalyses, in which we re-conceptualized COVID-19 clusters first as all counties included in SaTScan GINI-Optimized clusters, and second as all counties included in SpatialEpi clusters.
These two changes further decreased the magnitude of most coefficients as they likely more effectively fulfilled the purpose of controlling for spatial dependence.
The shifts were most signficant for the Ethnicity model, in which the Hispanic and Non-Hispanic white coefficients lost magnitude beyond the original confidence interval and the Hispanic coefficient is no longer significant.
Secondarily, the negative Above poverty level and Male coefficients both increased beyond the range of the original confidence intervals.

Overall, we can see that some coefficients remained significant and robust to changes in computational environment, data errors, and clustering criteria.
Robustly positive coefficients included Black, Native American, Non-Hispanic non-White, Below poverty level, and Female.
The Asian and Age 5-17 coefficients also remained just above 0.
All of these categories of people with disabilities would be considered intersectional with factors of vulnerability.
Conversely, some robustly negative coefficients indicate people with disabilities intersecting with non-vulnerable identities, such as white, Non-Hispanic White, Above poverty level, and Male.
Counter-intuitively, the two coefficients for elderly people with disability were also robustly negative.

In this third iteration of the study, I was curious how results would vary if the clustering criteria used in the GEE model was reduced into **just** state clusters and **just** relative risk score (from Spatial Epi) clusters.
The original study defined clusters in terms of these two variables, but I was curious on the intermediary steps of how clustering based on a single variable (instead of two) would impact the GEE results.
I was not expecting much, but to my surprise, the 95% confidence intervals of the Relative Risk Clusters and the State Fips Code Clusters are roughly in line with the prior reproduced results.
Compared to the five other GEEs (which all used the combined State-RR score), these two single-variable clustering GEEs had similar magnitude Betas that were similarly statistically significant.
Comparing the state clusters model to the relative risk model (the two additional models that I created), the state cluster criteria consistently had greater magnitudes and more uncertainty than the relative risk clusters.
The greater uncertainty of the state clusters model is not unexpected, since the size of each state is different.
Not all the states have the same geographic area, nor do they have the same demographic, socioeconomic, and capital characteristics.
Additionally, I suspect that the consistently greater magnitude of the coefficients from the state clusters model is likely due to the fact that relative to each other, some states had incredibly high rates of COVID-19 incidence (ex. Louisiana) while others had incredibly low relative rates (ex. VT), which leads to increased magnitudes.
However, this although this is purely hypothetical and I do not test this hypothesis.
But ultimately, neither of my new models had much effect on the ultimate outcome of the models.

The GEE models were used to test association between intracategorical rates of disability and COVID-19 incidence rates while accounting for spatial clustering of COVID-19 cases.
Again, the aim of these GEE models is to control for spatial dependence, which refers to the degree of spatial autocorrelation between independently measured values observed in geographical space.

### Interpret GEE Model

```{r residuals}
# create data frame with residuals
gee_resid <- data.frame(
  select(gee_or_clus_rpdep$models[[1]]$data, covid_rate, ss_clusID),
  data.frame(fitvals = gee_or_clus_rpdep$models[[1]]$fitted.values),
  data.frame(residual = gee_or_clus_rpdep$models[[1]]$residual),
  data.frame(working = residuals(gee_or_clus_rpdep$models[[1]], type = "working")),
  data.frame(response = residuals(gee_or_clus_rpdep$models[[1]], type = "response")),
  data.frame(pearson = residuals(gee_or_clus_rpdep$models[[1]], type = "pearson"))
) %>%
  mutate(
    my_working = (covid_rate - fitvals) / fitvals,
    my_pearson = response * (sqrt(gee_or_clus_rpdep$models[[1]]$prior.weights)) / sqrt(fitvals^2)
  ) %>%
  st_sf()

# working residual is the model residual (r) from gee, BUT HOW IS THIS CALCULATED?
# it is not simply the response residual normalized by the fitted value as the
# datascienceblog suggests
# response residual is: y(observed value) - fitted value
# my working residual normalizes response residual by fitted value, and effectively
# the code version of pearsons does the same because the prior weights are all 1
# if the datascienceblog is correct, the code pearson's residual should be divided by the square root of the fitted value.
# code: https://github.com/cran/geepack/blob/master/R/geeglm.R
# blog: https://www.datascienceblog.net/post/machine-learning/interpreting_generalized_linear_models
```

```{r map-residuals}
tm_gee_residuals <- tm_shape(gee_resid) +
  tm_polygons("response",
    title = "Race Model Residuals",
    style = "equal",
    n = 7,
    border.alpha = .2,
    lwd = 0.2,
    palette = "RdBu",
    legend.hist = FALSE,
    midpoint = 0
  ) +
  tm_shape(state) +
    tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5,
    legend.width = 0.25,
    legend.hist.size = 0.5,
    legend.hist.height = 0.15
  )

tm_gee_residuals
```

Calculate variance, covariance, correlation, and weights

```{r weights}
# calculate k number of observations per cluster
gee_resid <- gee_resid %>% 
  group_by(ss_clusID) %>% 
  mutate(k = n()) %>% 
  ungroup()

grps <- gee_resid %>% st_drop_geometry() %>% select(ss_clusID, residual = residual)

# create mask matrix
n <- length(gee_resid$ss_clusID)
# m <- matrix(nrow = n, ncol = n)

# this is very inefficient, but this makes matrix of equal clusID's:
# just need to omit the bottom-left of matrix and the diagonal
# selecting for rows 80-90 to help w debugging
m <- (outer(grps$ss_clusID, grps$ss_clusID, "==") &
  outer(rownames(grps), rownames(grps), "<"))

# calculate denominators
covar_d <- sum(m, na.rm = TRUE) - 1

# variance
v <- sum(grps$residual^2) / (n - 1)
# covariance
c <- sum(outer(grps$residual, grps$residual, "*") * m, na.rm = TRUE) / covar_d
# correlation
r <- c / v

# calculate weights
gee_resid <- gee_resid %>% 
  mutate(w = 1 / (1 + (k - 1) * r))
```

Map each county's weight in GEE model.

```{r map-weights}
tm_gee_weights <- tm_shape(gee_resid) +
  tm_polygons("w",
    title = "Race Model Weights",
    style = "jenks",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Oranges",
    legend.hist = FALSE,
    midpoint = .5
  ) +
  tm_shape(state) +
    tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5,
    legend.width = 0.25,
    legend.hist.size = 0.5,
    legend.hist.height = 0.15
  )

tm_gee_weights

# re
```

```{r save-figures, eval = F}
# save figures as image files
# obviously this could be made into a for loop
# add height, width, and dpi parameters to tmap_save to meet criteria for particular publications.
tmap_options(unit = "in")
tmap_save(tm_author_clusters, here("results", "figures", "tm_author_clusters.png"))
tmap_save(tm_covid_rates, here("results", "figures", "tm_covid_rates.png"))
tmap_save(tm_disability_rates, here("results", "figures", "tm_disability_rates.png"))
tmap_save(tm_spatialepi_clusters, here("results", "figures", "tm_spatialepi_clusters.png"))
tmap_save(tm_spatialepi_gini, here("results", "figures", "tm_spatialepi_gini.png"))
tmap_save(tm_spatialepi_hier, here("results", "figures", "tm_spatialepi_hier.png"))
tmap_save(tm_spatialepi_cluster_risk_class, here("results", "figures", "tm_spatialepi_cluster_risk_class.png"))
tmap_save(tm_spatialepi_local_risk_class, here("results", "figures", "tm_spatialepi_local_risk_class.png"))
ggsave(here("results", "figures", "plot_coefficients.png"), geewhisker_fig)
```

# Discussion

## Bias and threats to validity

Given the research design and primary data to be collected and/or secondary data to be used, discuss common threats to validity and the approach to mitigating those threats, with an emphasis on geographic threats to validity.

**Edge effects** were not accounted for in the analysis.

The analysis created **spatial subgroups** based on **spatial clustering**.
The purpose of this grouping was to control for **spatial heterogeneity** between regions (defined as states) and **spatial correlation** within regions using GEE models.
The spatial subgroups based on state and COVID-19 risk were specified in the attribute transformation subsection above.

This analysis accounted for **first order spatial effects** of regional difference by including states in the clustering criteria for GEE models.
The analysis accounted for some **second order spatial effects** by including a relative risk score for COVID-19 spatial clusters in the clustering criteria for GEE models.
The analysis did not account for **spatial anisotropies**, as the Kulldorff spatial scan statistic was constrained to circular non-directional clusters.

The study used a cross-sectional design, aggregating cases across the full **temporal extent** from 1/22/2020-8/1/2020.
The **temporal support** was inconsequential, as both the COVID-19 cases and disability sociodemographic data were aggregated across time for the full temporal extent.
**Temporal effects** were not conceptualized, measured, or accounted for.
There is potential for error and uncertainty in areas experiencing rapid socio-demographic change due to the **temporal coverage** of the socio-demographic data, as it was derived from ACS estimates from 2014 to 2018, prior to the onset of the COVID-19 pandemic.

There was no documentation of any **data exclusion** based on attribute criteria in the original study.
No **outliers** were analyzed or accounted for in the study.
No **weights** were applied in the study.

## Unplanned deviations

Some minor unplanned deviations stemmed from small operational errors or the constraints of a short journal article for describing the data and methodology of a research project.
These deviations could be resolved with computational notebooks, and include the resolution of some missing data for Rio Arriba County, New Mexico, mapping disability rates, and resolving data errors

We planned to test the independent variables for normality prior to using the Pearson's r correlation coefficient for bivariate tests of correlation between the independent variables and COVID-19 incidence rates.
Most of the independent variables had significantly non-normal distributions; and therefore our reproduction has used the nonparametric Spearman's rank correlation coefficient for bivariate tests of correlation between the independent variables and COVID-19 incidence rates.
In order to better understand the geographic patterns underlying the correlations between disability and COVID-19, we also visualized disability rates by county.

The original study did not directly report details for the results of the Kulldorff spatial scan statistic for COVID-19 clusters beyond the number of clusters detected.
In order to compare our reproduction using the SpatialEpi package to the original study using SaTScan software, we also ran the spatial scan statistic in SaTScan.
SaTScan produced three outputs: 1.
text file report of the analysis with information on each cluster 1.
vector layer of circle polygons with the center and radius of each cluster, ID of the county at the center of the cluster, and a relative risk score for the cluster.
The layer contained one circular polygon feature for each cluster (see figure 4), identifying only the county at the center of the cluster.
1.
vector layer of points of the centroids of each county in any cluster, including a unique cluster ID, relative risk score of the cluster, and relative risk score of the location (the county).

We compared our results to the original publication, data files provided by the author, and the number of clusters for GEE models.
We exactly reproduced the original author's data files using our data inputs and SaTScan software.
In order to better understand how the original research used the Kulldorff spatial scan statistic, we decided to create an additional map to visualize the spatial distributions of COVID-19 clusters resulting from SaTScan software.
We created maps visualizing the spatial clusters of COVID-19 incidence based on the output of SpatialEpi and SaTScan.
We discovered that the original study most likely operationalized COVID-19 risk as the local relative risk of the county at the center of the cluster using the vector layer of circle polygons enumerated as the second output above.
This operationalization excluded all but the center county of each cluster and assigned the other counties to the lowest risk category.
For example, SaTScan identified a circular cluster encompassing all of Rhode Island and most of Massachusetts, Connecticut, and Long Island.
However, the original operationalization of COVID-19 risk only considered the relative risk of the county at the center of the cluster: Washington County, Rhode Island.
All other counties were classified as minimal risk.
We also discovered that unlike SaTScan, the SpatialEpi package in R did not calculate local or cluster relative risk.

Therefore, we changed our conceptualization of COVID-19 clusters to include all counties within any cluster.
We calculated relative risk for localities (counties) and clusters as `(incidence rate within the county) / (incidence rate outside of the county)`.
We calculated the Kulldorff spatial scan statistic in `SpatialEpi` and then calculated local relative risk for any county within any of the resulting clusters.
Once we joined the spatial clustering data to all counties with socio-demographic and COVID-19 data, we observed that all counties outside of any cluster had `null` or `na` data for COVID-19 risk.
We inspected the original author's data to determine how to classify these counties, and accordingly assigned them to the lowest risk class: `1`.
We created a map showing the relative risk score of each county (Figure 5) for comparison with the original analysis and to assess its appropriateness for GEE clusters.
We proceeded to combine the local COVID risk score with State ID's for use as the GEE clustering ID and to run the GEE models.

At this point we observed the spatial heterogeneity of local relative risk (Figure 5) and considered the original purpose of calculating clusters and relative risk classes, which was to control for spatial dependence within states and COVID-19 hotspots.
Out of concern to balance a need to control for spatial dependence while not accounting for too much variation within the dependent variable, we decided to re-conceptualize the classification of COVID risk using cluster-based relative risk.
To calculate the cluster relative risk, we created a list of unique cluster IDs and extracted the counties contained within each cluster from `SpatialEpi` output and calculated cluster relative risk as: `(incidence rate within the cluster) / (incidence rate outside of the cluster)`.
We then classified the cluster relative risk with the original method, illustrated in Table 2.
We re-classified the GEE clustering IDs based on state and cluster relative risk class and recalculated the generalized estimating equations using this alternative conceptualization of COVID-19 risk.

Upon discovering different results in all of our reproduction GEE models compared to the original study, we added new models to assess the extent to which the different computational environment was causing differences in our results.
We therefore ran another set of the five GEE models using data provided by the original author, expecting to find identical results.

# Discussion

Our reproduction of the original study was partially successful, leading to similar, but inexact results compared to the original study.
A portion of the inexactitude may be attributed to differences in the computational environments (ie. SaTScan vs. Spatial Epi).
However, we have also reanalyzed the study and tested its robustness by changing some research parameters.
Our results suggest support for the conclusions of the original study, but also emphasize the importance of reproduction studies to critically review the full details of the research design, to evaluate internal validity, and to test for uncertainty and robustness to key parameters.

The choropleth map we made in the **first part** of the reproduction analysis (Figure 2) reveals an identical spatial pattern to that of the original study's Figure 1, confirming the equivalence of our dependent variable with that of the original study.
Both maps revealed that COVID-19 cases were distributed unevenly across space.
In particular, cases were more prevalent in the southern part of the country, in the metropolitan areas of the northeast, Chicago, and California, and in some rural areas, including eastern Washington, New Mexico, and Iowa.
Prior to Chakraborty's bivariate analysis of disability and COVID-19 incidence, we also mapped the spatial distribution of disability (Figure 3).
This spatial visual analysis reveals many regions in which disability rates are high but COVID-19 incidence was still low, including rural New England, Appalachia, and northern Michigan.
Conversely, many hotspots of COVID-19 incidence had low rates of disability, including metropolitan New England, South Florida, and Chicago.
The two spatial distributions help explain the negative bivariate relationship between disability rates and COVID-19 incidence.

The summary statistics for the **second part** of the reproduction analysis matched perfectly with those of the original study, confirming that the reproduction uses identical original data.
The original study used Pearson's correlation to test bivariate relationship between variables that are non-normally distributed, and we revised this to use the nonparametric Spearman's correlation coefficient.
Our reanalysis of the correlations generally found identical directions and increased magnitudes, confirming the bivariate correlations and significance levels of most of the socio-demographic subcategories.
However, biological sex may not be correlated with COVID-19 incidence rates, as the percentage of females with disabilities changes direction and significance.

The Kulldorff spatial scan statistic varied significantly between the original study (using SatScan) and our reproduction and re-analysis (using open source SpatialEpi) with regards to selection of secondary clusters, interpretation of clusters, and relative risk scores.
SatScan and SpatialEpi identify the same most likely cluster, but different sets of secondary clusters.
They also employ slightly different distance calculations, where SatScan calculates a great circle spherical distance and SpatialEpi approximates a kilometer grid based on simplified conversions of latitude and longitude degrees into a planar grid using kilometer units.
SaTScan uses GINI statistics to select secondary clusters which maximize the difference between the population within clusters and the population outside of clusters, allowing for geographic overlap and finding 96 total clusters.
The original study used this default secondary cluster selection method.
SpatialEpi selects the most likely secondary clusters while excluding clusters with any geographic overlap, finding 135 total clusters.
This difference of parameters and computational environment explains the two different sets of clusters.
The different sets of secondary clusters largely agree in terms of the most likely cluster in a region and diverge in terms of overlapping, small, and less likely clusters.

The original study classified COVID risk using a local relative risk score for the county at the center of each cluster (Figure 4).
Considering the relatively small number of clusters (102) compared to counties (3108), this method implies that the majority of counties in each state are classified as single low-risk clusters for the GEE analysis, and the remaining 53 clusters were composed of just a few counties at the centers of various COVID hotspots.
When we extended the interpretation of clusters to use the local relative risk score of any county within a cluster (Figure 5), we find significantly more variance in COVID risk within states, resulting in 139 unique GEE clusters.
However, this conceptualization apparently created GEE clusters defined in part by an ordinal classification of the dependent variable -- COVID incidence.
Considering that the original motivation for using GEE models was to account for spatial dependence within states (accounting for COVID response policy) and within COVID hotspots (accounting for the uneven geographic diffusion of the pandemic).
Therefore, a cluster-based relative risk classification seemed more appropriate than a local county-based relative risk classification, by applying the same risk level to the entire COVID cluster and allowing the GEE models to analyze variance within the clusters.
However, many of the most likely clusters extend across multiple states (see Figure 6, especially the southern states from Louisiana to South Carolina).
This resulted in creation of GEE clusters composed of every county within a state, amounting to 111 unique GEE clusters overall.

Our analysis of COVID-19 clusters in the context of controlling for spatial dependence has revealed several challenges and limitations to application of Kulldorff spatial scan statistics across different computational environments.
These include inconsistent methods for determining secondary clusters, limitation to circular or ellipsoidal cluster shapes, inclusion of single-county clusters, and choosing a method to control for spatial dependence in COVID 19 risk without controlling for too much of the variance in the dependent variable.
Ideally, we would have liked to use a GINI-based secondary cluster detection to classify counties by their maximum cluster-based relative risk score, but this particular conceptualization is not possible in available R packages.

In the **third part** of our reproduction analysis, the results from each of the five (plus two single-variable clustering models) GEE models were largely consistent with Chakraborty's, suggesting robustness to modeling decisions with regards to GEE clusters.
However, a few independent variables exhibited instability across models, suggesting weak or spurious relationships.
We ultimately modeled three different scenarios: 1.
We reproduced the original analysis with the original data while changing only the computational environment to geepack in R.
2.
We reproduced the Kulldorff spatial scan in R and reanalyzed the data by applying a local relative risk score to every county within any cluster.
3.
We reproduced the Kulldorff spatial scan in R and reanalyzed the data by applying a cluster relative risk score to every county in a cluster.

We found that reproducing the analysis with **geepack** resulted in slightly different GEE results than the original study, even when using data provided by the author from the original study.
This suggests that the computational environments differ in their implementation of GEE, a method for which there are multiple approaches to parameter estimation.
Still, the coefficients trend in the same direction with similar magnitudes, with the exception of the 35-64 age group.
In our model that assigns local relative risk scores for all counties in clusters, the coefficients are weaker while more of the variance in COVID-19 incidence is accounted for in the GEE clustering method.
When we moved to cluster-level relative risk scores, the coefficients again performed more similarly to the original publication.
Although the results of the original publication and the cluster-level relative risk model version are similar, the model conceptualization is very different.
The original model excludes most counties from COVID-19 hotspots, assigning them the lowest level of risk and inadvertently avoiding the problem of controlling for too much variance in COVID-19 through definition of clusters.
Conversely, the reanalyzed cluster-based model includes most counties in COVID-19 hotspots at the same risk level.
The results are similar because in both scenarios the majority of counties in each state are aggregated into the same cluster.

Comparing across each version of the model, we observed that most variables exhibit stability in the direction and magnitude of the coefficients, even in the two additional models with single variable clustering mechanisms (just state and just RR scores).
However, some variables are less stable -- especially the black and other race categories, Hispanic ethnicity, and some age groups less affected by severe COVID-19 cases (18-34 and 35-64).
Therefore, these variables are more sensitive to the design of GEE clusters, warranting further investigation to evaluate the internal validity of these relationships with regard to the model assumptions of GEE.

We confirmed support for Chakraborty's conclusion that although the overall disability percentage is negatively associated with confirmed COVID-19 cases, intra-categorical analysis with geographic GEE clustering reveals that socio-demographically disadvantaged PwDs were significantly over-represented in counties with higher COVID-19 incidence.
We found the same direction for each independent variable of intra-categorical disability and COVID-19 incidence.
However, we found weaker significance levels for the Black category and the Hispanic or Latino category.
We found stronger significance levels for the 18-34 and 35-64 age categories.
Differences in our results can be attributable to our different approach to classifying relative risk scores and our different computational environments.

Closer inspection of the clusters for the GEE models revealed a highly skewed distribution of cluster sizes, with most clusters containing very few counties and a few clusters containing 50 or more counties.
GEE weights observations based on the number of observations within a cluster and the degree of correlation in the standard errors within clusters.
Therefore, counties within small clusters (e.g. the counties of Rhode Island or the few counties with high COVID risk classification) will have much larger weights than counties within large clusters (e.g. counties with low risk classifications in large states).
The combination of very different cluster sizes and use of a clustering criteria related to the dependent variable warrant further analysis with alternative approaches to controlling for spatial dependence.
We quickly diagnosed whether the clustering method was significantly skewing the estimated coefficients by running non-clustered generalized linear (GLM) models for each of the hypotheses H2.1 through H2.5.
Fortunately, we found the GLM coefficients to be consistent, and in most cases stronger, than the GEE model coefficients.
Future replications of this research should consider selecting an alternative inferential statistical model which explicitly accounts for spatial dependence.

# Conclusion

With regards to the **overall conclusions** and **research design**, we agree with the original author's cautious interpretation emphasizing "county-level associations" and the need for "additional data and analysis".
There are at least five sources of uncertainty in this study: ecological fallacy, scale dependency, modifiable areal unit problem, variable measurement, and spatial dependency.
There is a risk of ecological fallacy with this research design, whereby county-level statistics for the whole population should not be interpreted as definitive inferential proof of individual-level relationships, especially for populations comprising no more than one third of any county.
Counties are not weighted by population.
Therefore, in this analysis a few people with disabilities in a rural county are collectively weighted as one observation with equal weight to many people with disabilities in an urban county as another observation.
There is a real possibility that the study findings are scale-dependent, but it is also impossible to replicate the study using a finer spatial support without also limiting the extent to one or more adjacent states with sub-county data on COVID-19.
The modifiable areal unit problem (MAUP) may also be a source of uncertainty, especially when considering the variable population sizes of counties, which all carry equal weights in the analysis.
Finally, there are well-known problems with the testing and reporting of COVID-19 cases across time and space during the pandemic in the United States, and there is also uncertainty in American Community Survey (ACS) data, particularly when cross-tabulating multiple demographic characteristics.
This study partially mitigates measurement uncertainty by aggregating data across time (more than one year of the pandemic and the five-year ACS estimate) and into relatively large geographic units (counties).
The study accounts for spatial dependency using the GEE models to cluster county observations by state and COVID risk classification.
However, the GEE method simply uses correlation matrices to weight each county observation according to the number of observations in its cluster and the overall within-cluster correlation of standard errors.
The spatial dependence between counties in different clusters is not modelled, even if the counties are adjacent to each other.

In sum, although some of our results differed from Chakraborty's because of differences in analytical methods, conceptualizations, and computational environments, our reproduction results still generally corroborate the findings of the original study suggest that PwDs are likely to experience multiple jeopardy based on the convergence of their disability, racial/ethnic minority, and poverty status.
We reiterate Chakraborty's carefully limited interpretation emphasizing county-level relationships and the need for additional data and research, because the estimated relationship at the county level may not hold at the individual level.
Interpretation of the results were based on aggregate statistics at the county level and on statistical methods which produce approximate estimates, not inferences.
Further work is needed to reliably infer relationships between minority PwDs and COVID-19 morbidity and mortality, especially at finer geographic scales.
Further replication and reanalysis work would be beneficial on this topic to further test the robustness of Chakraborty's findings.
Future versions could more thoroughly vary the structural criteria of how counties are clustered (ie. using variables beyond just state and relative risk statistics) to better account for inter-county and intra-state correlations in COVID-19 cases.
Ideally, a package gets added to R in the future that provides GINI-based secondary cluster detection to classify counties by their maximum cluster-based relative risk score, which would allow us to more directly test results and compare to the SatScan software used in the original report.

### Rationale for updated report

This is the **THIRD** version of our reproduction report.
The first, registered at <https://doi.org/10.17605/OSF.IO/647EX> on July 22, 2022, represented our best knowledge of the study at that time.
Subsequently, we improved our approaches to reproduction studies by revising pre-analysis plans and post-analysis reports into legible code RMarkdown documents.
The second change prompted us to re-order some content to flow more linearly with the sequencing required by code, and prompted us to digitize (if necessary) and import results from the original research into Rmarkdown for quantitative comparison to the reproduction study.
These comparisons led to further insights and research into discrepancies between the original and reproduced Pearsons's correlations between various forms of the Kulldorff spatial scan statistic.
We also discovered an improved method for comparing the results of generalized linear models by plotting all of the model results on a dot-whisker graph using the dotwhisker package.
This third version of the reproduction report accomplished several changes, most of which were aesthetic.
First, many printed tables were converted to formal tables using Kable and Kable Extra.
Second, specific sections (including the discussion and conclusion) were rearranged and moved within the report to improve readability, organization, and clarity.
Third, several map visualization aesthetics were tweaked to better spread the color gradient and thus emphasize minimums and maximums.
Fourth, I attempted to run two additional GEE analyses that utilized single variable clustering criteria instead of the "taken for granted" combination cluster IDs: clustering by just state and clustering by just relative risk score (from Spatial Epi).
For this last step, I utilized the corrected (or fixed) COVID-19 incidence rate for both additional GEE models.
